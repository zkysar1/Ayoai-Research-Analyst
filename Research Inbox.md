# ğŸ“‹ Research Inbox

- [ ] **Wow, for behavior trees... this one only two years old and is fantastic. I need....**
  > ğŸ“ https://arxiv.org/pdf/2008.11906

- [ ] **Here is a video talk on it that he posted about Omni-epic**
  > ğŸ“ [Jeff Clune (@jeffclune) on X](https://x.com/jeffclune/status/1800260865955934282?s=19)

- [ ] **Suspending Disbelief: Bringing Your Characters to Life with Better AI. This has a really cool social game I need to build!**
  > ğŸ“ [Suspending Disbelief: Bringing Your Characters to Life with Better AI](https://www.gdcvault.com/play/1012422/Suspending-Disbelief-Bringing-Your-Characters)

- [ ] **Watch Jim Fan on foundation agent**
  > ğŸ“ [Jim Fan (@DrJimFan) on X](https://x.com/DrJimFan/status/1770848955519107345?s=20)

- [ ] **Jen thinks we should map out the brain. Abs the processes that the Brian does,  and start from there**

    - [ ] **Like, is this the brain mapping?**
    > ğŸ“ [TuringPost (@TheTuringPost) on X](https://x.com/TheTuringPost/status/1802864154778464719?s=19)

      - [ ] **Yeah,  wow, I need to study this!!!  Great find.   How did I find that?!  [What is Joint Embedding Predictive Architecture (JEPA)?](https://www.turingpost.com/p/jepa)**

- [ ] **Cool demo - webpages agent**
  > ğŸ“ [Josh Miller (@joshm) on X](https://x.com/joshm/status/1753129075487478157?s=19)

- [ ] **Hmm, book?!**
  > ğŸ“ [Irena Cronin (@IrenaCronin) on X](https://x.com/IrenaCronin/status/1802870224242278482?s=19)

- [ ] **Like dejavu.   Like,  my send is constantly pulling up situations that are similar, even when I'm not asking for it....   like starting at a screen I can tell when something is similar even when not asking myself that question.  Hmm**

- [ ] **Open source meta?!**
  > ğŸ“ [AI at Meta (@AIatMeta) on X](https://x.com/AIatMeta/status/1803107817345393136?s=19)

- [ ] **Copy those adjacent things. From Twitter, those things about edges. The edges are very interesting. This is what I said that I like: Wow! ğŸ¤¯ Ok, you got me going. For example, I now wonder if non physical things also have these edges. Say memory, the difference between adjacent points on the "x" spectrum where x could mean spatial, social, or personality, etc., Spectrums. Memory recal could include these.**
  > ğŸ“ [AGIHound (@TrueAIHound) on X](https://x.com/TrueAIHound/status/1803172055447380453)

- [ ] **This seems interesting.  Maybe get gpt to summerize it**
  > ğŸ“ [The Flow State: Turn Life Into An Addictive Video Game - Dan Koe](https://thedankoe.com/letters/the-flow-state-turn-life-into-an-addictive-video-game/)

    - [ ] **Wait,  this one too**
    > ğŸ“ [Discovery of Memory "Glue" Explains Lifelong Recall - Neuroscience News](https://neurosciencenews.com/genetics-memory-recall-26377/)

- [ ] **World models with tockenization**
  > ğŸ“ [\[2406.19320\] Efficient World Models with Context-Aware Tokenization](https://arxiv.org/abs/2406.19320)

- [ ] **Symbolic agents**
  > ğŸ“ [\[2406.18532\] Symbolic Learning Enables Self-Evolving Agents](https://arxiv.org/abs/2406.18532)

- [ ] **Learning agents**
  > ğŸ“ [\[2406.14228\] EvoAgent: Towards Automatic Multi-Agent Generation via Evolutionary Algorithms](https://arxiv.org/abs/2406.14228)

- [ ] **You member things more that they are closer to you.  Like, if you watch someone get stabbed on TV pg 13, vs r, vs real wife, vs your wife,  vs your self.   Escalating things off memory**
  ğŸ·ï¸ COMPUTER, EVENING

- [ ] **Cool prompt**
  > ğŸ“ [Rohan Paul (@rohanpaul_ai) on X](https://x.com/rohanpaul_ai/status/1812295914566176866?s=19)

- [ ] **From Text to Life: On the Reciprocal Relationship between Artificial Life and Large Language Models**
  > ğŸ“ [\[2407.09502\] From Text to Life: On the Reciprocal Relationship between Artificial Life and Large Language Models](https://arxiv.org/abs/2407.09502)

- [ ] **A Survey of Prompt Engineering Methods in Large Language Models for Different NLP Tasks**
  > ğŸ“ [\[2407.12994\] A Survey of Prompt Engineering Methods in Large Language Models for Different NLP Tasks](https://arxiv.org/abs/2407.12994)

- [ ] **Symbolic Learning Enables Self-Evolving Agents**
  > ğŸ“ [\[2406.18532\] Symbolic Learning Enables Self-Evolving Agents](https://arxiv.org/abs/2406.18532)

- [ ] **Genie: Generative Interactive Environments**
  > ğŸ“ [\[2402.15391\] Genie: Generative Interactive Environments](https://arxiv.org/abs/2402.15391)

- [ ] **Wait,  is this my competitor now?!**
  > ğŸ“ [Aidan McLau (@aidan_mclau) on X](https://x.com/aidan_mclau/status/1818071890755469365?s=19)

- [ ] **LLMs Can't Plan, But Can Help Planning in LLM-Modulo Frameworks**
  > ğŸ“ [\[2402.01817\] LLMs Can't Plan, But Can Help Planning in LLM-Modulo Frameworks](https://arxiv.org/abs/2402.01817)

- [ ] **Center for brain health?!**
  > ğŸ“ [Center for BrainHealth teams up with AWS to grow Charisma program using generative AI and cloud gaming | Amazon Web Services](https://aws.amazon.com/blogs/gametech/center-for-brainhealth-teams-up-with-aws-to-grow-charisma-program-using-generative-ai-and-cloud-gaming/)

- [ ] **Advanced reasoning agent q?!**
  > ğŸ“ [\[2408.07199\] Agent Q: Advanced Reasoning and Learning for Autonomous AI Agents](https://arxiv.org/abs/2408.07199)

- [ ] **Competitor convai?!   Damnnn**
  > ğŸ“ [convai](https://convai.com/pricing)

    - [ ] **They don't decide themselves though they only take direction**

- [ ] **This taskgen  looks cool!**
  > ğŸ“ [TaskGen: A Task-Based, Memory-Infused Agentic Framework using StrictJSON | alphaXiv](https://www.alphaxiv.org/abs/2407.15734v1)

- [ ] **The question, what is best restaurant?  Goal synthesizer tells how to evaluate the data,  but who is telling the goal synthizer to do? Lifing polls**

- [ ] **Holy yikers what is this shared conversation?!  Transcend consciousness**
  > ğŸ“ [Parzival - âˆ/acc (@whyarethis) on X](https://x.com/whyarethis/status/1834421088073515215?s=19)

- [ ] **Who wrote this paper?!  Agent memories, and workflow, hmm**
  > ğŸ“ [Carlos E. Perez (@IntuitMachine) on X](https://x.com/IntuitMachine/status/1835457884844658786?s=19)

- [ ] **The ai scientist**
  > ğŸ“ [\[2408.06292\] The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery](https://www.arxiv.org/abs/2408.06292)

- [ ] **The use of embeddings by models has also grown rapidly, driven by the growing demand for semantic understanding, whether through NLP, computer vision, or recommendation systems. This motivated us to build out aÂ vector databaseÂ to efficiently store and retrieve vectors as high-dimensional points. The vector database has enabled fast nearest neighbor lookups to power capabilities such as multimodal search and content violation detection.**

- [ ] **Tribuo is a machine learning library written in Java that provides tools for classification, regression, clustering, model development, and other capabilities. LangChain4j is a Java version of the LangChain framework for building applications powered by large language models (LLM); its goal is to simplify the integration of LLMs into Java applications. And CoreNLP offers a suite of tools for doing natural language processing in Java.**

- [ ] **Human-like Affective Cognition in Foundation Models**
  > ğŸ“ [\[2409.11733\] Human-like Affective Cognition in Foundation Models](https://arxiv.org/abs/2409.11733)

- [ ] **[LEVELS (Basic Version)](https://youtu.be/kse87ocS0Uo?si=I95IL6IeJcFH5870) -  - This guy chats about levels of thinking.   He includes Piaget and Maslow.  I just though his diagram was interesting/how he organizes his information**

- [ ] **Wow, got to read this!!!  Making Large Language Models into World Models with Precondition and Effect Knowledge -  -**
  > ğŸ“ [\[2409.12278\] Making Large Language Models into World Models with Precondition and Effect Knowledge](https://arxiv.org/abs/2409.12278)

- [ ] **Main competitors are Convai and Altera**

- [ ] **Generate 3d objects for Roblox!**
  > ğŸ“ [Roblox 3D Assets Generator v1 - a Hugging Face Space by ThomasSimonini](https://huggingface.co/spaces/ThomasSimonini/Roblox-3D-Assets-Generator-v1)

- [ ] **Cool memory thing to listen to,  this looks really good!!**
  > ğŸ“ [Self-Narrative and Self Improvising Memory](https://youtu.be/d9rAAKhxf2M?si=akRhZeHekMivslHN)

- [ ] **I need to check out and use nptebooklm**
  > ğŸ“ [Andrej Karpathy (@karpathy) on X](https://x.com/karpathy/status/1840137252686704925?s=19)

- [ ] **Cool memory graph!!  This is what I want,I think,  no?!!!!!   AriGraph: Learning Knowledge Graph World Models with Episodic Memory for LLM Agents -  -**
  > ğŸ“ [\[2407.04363\] AriGraph: Learning Knowledge Graph World Models with Episodic Memory for LLM Agents](https://arxiv.org/abs/2407.04363)

- [ ] **Altera framework**
  > ğŸ“ https://openai.com/index/altera/
  
  <details>
  <summary>ğŸ’¬ Comments (1)</summary>
  
  **Comment 1:** 
  
  </details>

- [ ] **Look at this scenario selector!  Interesting chart in how to selector scenario?**
  
  <details>
  <summary>ğŸ’¬ Comments (1)</summary>
  
  **Comment 1:** 
  
  </details>

- [ ] **Chain of symbol prompting?  Less tokens!!**
  > ğŸ“ [\[2305.10276\] Chain-of-Symbol Prompting Elicits Planning in Large Langauge Models](https://arxiv.org/abs/2305.10276)

- [ ] **Different agent frameworks to review in a picture**
  > ğŸ“ [Eduardo Ordax (@ordax) on X](https://x.com/ordax/status/1843006110074274148?s=19)
  
  <details>
  <summary>ğŸ’¬ Comments (1)</summary>
  
  **Comment 1:** 
  
  </details>

- [ ] **Omg, check out the entangled brain!!  Free book here**
  > ğŸ“ [InÃªs HipÃ³lito (@ineshipolito) on X](https://x.com/ineshipolito/status/1645002923573747712?s=19)
  
  <details>
  <summary>ğŸ’¬ Comments (2)</summary>
  
  **Comment 1:** https://direct.mit.edu/books/oa-monograph/5490/The-Entangled-BrainHow-Perception-Cognition-and
  
  **Comment 2:** 
  
  </details>

- [ ] **Very cool prompt here!! For reasoning**
  > ğŸ“ [Jeremy Nguyen âœğŸ¼ ğŸš¢ (@JeremyNguyenPhD) on X](https://x.com/JeremyNguyenPhD/status/1842888290376261668?s=19)

- [ ] **Wait, asking the llm to generate check lists improves performance!  Holy cow, that makes a lot of sense.**
  > ğŸ“ [\[2410.03608\] TICKing All the Boxes: Generated Checklists Improve LLM Evaluation and Generation](https://arxiv.org/abs/2410.03608)

- [ ] **Read competitor.  Good stuff in here about what I'm building.**
  > ğŸ“ [Inworld AI (@inworld_ai) on X](https://x.com/inworld_ai/status/1843748821505110419?s=19)

- [ ] **Wait,  should I try this?!  Ditto. What is flask?**
  > ğŸ“ [mcbagz (@Bagz_Tech) on X](https://x.com/Bagz_Tech/status/1847345611919524042?s=19)

- [ ] **GameTraversalBenchmark: Evaluating Planning Abilities Of Large Language Models Through Traversing 2D Game Maps**
  > ğŸ“ [\[2410.07765\] GameTraversalBenchmark: Evaluating Planning Abilities Of Large Language Models Through Traversing 2D Game Maps](https://arxiv.org/abs/2410.07765)

- [ ] **This one builds domain files: LLM+P [Liu et al., 2023a] [\[2304.11477\] LLM+P: Empowering Large Language Models with Optimal Planning Proficiency](https://arxiv.org/abs/2304.11477)**

- [ ] **https://notebooklm.google.com/notebook/f5b07e9a-322f-4189-bf66-c73a2240491e/audio**
  > ğŸ“ My first pod cast using notebook llm on my big research paper

    - [ ] **2 takeaways, so one takeaway is that they wanted me to include life Poles because that would give different set of problems, we could solve and the next takeaway is that they brought up multi agent communication and sharing behavior trees. That's gonna be critical.  They also brought up open souls as a name**

- [ ] **What's this memary?!**
  > ğŸ“ [GitHub - kingjulio8238/Memary: The Open Source Memory Layer For Autonomous Agents](https://github.com/kingjulio8238/Memary)

- [ ] **This would be cool to listen to if I had an hour,about the guy who built baby agi**
  > ğŸ“ [Dan Shipper ğŸ“§ (@danshipper) on X](https://x.com/danshipper/status/1849113504537845912?s=19)

- [ ] **Wait,  what the heck is this?!  Bolt.new to make a website**
  > ğŸ“ [Tomek SuÅ‚kowski (@sulco) on X](https://x.com/sulco/status/1848883749510959241?s=19)

- [ ] **This is how to use computer with anthropic!**
  > ğŸ“ [Nick Dobos (@NickADobos) on X](https://x.com/NickADobos/status/1849249533492158945?s=19)

- [ ] **This looks cool to listen too**
  > ğŸ“ [Carlos E. Perez (@IntuitMachine) on X](https://x.com/IntuitMachine/status/1850282844347916394?s=19)

- [ ] **Research paper tool, it does tesearch papers.**
  > ğŸ“ [Heather Cooper (@HBCoop_) on X](https://x.com/HBCoop_/status/1849876665481990217?s=19)

- [ ] **What is this?!  Llm reasoner?**
  > ğŸ“ [GitHub - maitrix-org/llm-reasoners: A library for advanced large language model reasoning](https://github.com/maitrix-org/llm-reasoners)

- [ ] **What is a cognitive model?!  Fine tuned on llama.  Holy shit I want to use this.**
  > ğŸ“ [Marcel Binz (@marcel_binz) on X](https://x.com/marcel_binz/status/1850806691958313160?s=19)

- [ ] **This is a really cool take!  There are production a things and control things.  Figure 2. (a) A typical hierarchical arrangement of control mechanisms. (b) A heterarchical arrangement. Sensory inputs are represented by dotted arrows, control by solid arrows. Edge-ended lines indicate inhibition.**
  > ğŸ“ https://royalsocietypublishing.org/doi/10.1098/rstb.2019.0751

    - [ ] **In the case of decision-making, the core elements are: (1) selecting between alternatives based on making measurements of both internal and external conditions and (2) evaluating those by means of norms embodied in the control mechanism, which are ultimately rooted in the maintenance of the organism.**
    - [ ] **Main take!!  mechanisms are systems of constraints that restrict the flow of free energy to perform work.  Constraints restrict what movements are possible.  However, as Hooker [26] makes clear, constraints also open up possibilitiesâ€”water constrained by a pipe can reach a destination much further away than if it is not so constrained.**
    - [ ] **The operations of a control mechanism in turn can be modulated by other control mechanisms that operate on flexible constraints in the first control mechanism. Multiple control mechanisms can be assembled into an architecture capable of determining multiple different specific responses as needed to maintain the complex biological organization constituting an organism.**

- [ ] **Very cool research: Building Altruistic and Moral AI Agent with Brain-inspired Affective Empathy Mechanisms -  -**
  > ğŸ“ [\[2410.21882\] Building Altruistic and Moral AI Agent with Brain-inspired Affective Empathy Mechanisms](https://arxiv.org/abs/2410.21882)

- [ ] **A Framework for Collaborating a Large Language Model Tool in Brainstorming for Triggering Creative Thoughts**
  > ğŸ“ [\[2410.11877\] A Framework for Collaborating a Large Language Model Tool in Brainstorming for Triggering Creative Thoughts](https://arxiv.org/abs/2410.11877)

- [ ] **Holy shit i want to dig into this more...  [AGIHound (@TrueAIHound) on X](https://x.com/TrueAIHound/status/1855820531716518214?s=19)**

    - [ ] **What is this and the thousand brains theory?**
    > ğŸ“ [Home | Numenta](https://www.numenta.com/)
    - [ ] **Watch this video!!  This is a core video, hmmm**
    > ğŸ“ [2021/11 - Initial Outline of the Requirements of Monty Modules](https://youtu.be/fBpNe0DhfPE?si=yuGTLHKECzhV2siU)
    - [ ] **Is more how to percieve, than how to act!!  I will need this when I go to prrception...**

- [ ] **What about the monte Carlo tree search?  This company is doing it:  [Nous Research (@NousResearch) on X](https://x.com/NousResearch/status/1856417886526460013?s=19)**

- [ ] **First return, then explore**
  > ğŸ“ [First Return Then Explore](https://youtu.be/0hgarA3EvqA?si=cAqY-9Qmq9VYXEdT)

- [ ] **Generative Agent Simulations of 1,000 People -  -**
  > ğŸ“ [\[2411.10109\] Generative Agent Simulations of 1,000 People](https://arxiv.org/abs/2411.10109)

- [ ] **What?!!  Thousand brains project**
  > ğŸ“ [ThousandBrainsProject (@1000brainsproj) on X](https://x.com/1000brainsproj/status/1859238060891779392?s=19)

    - [ ] **Watched the videos.   They are focused hard on perception.   Not sure they got this right.   I like the voting idea and such,  but meh**
    - [ ] **Evidence count (like how much hypothised reward meets expected, something like that) is their reward, 1000 brains is still calculating a reward there.  Stick with what i am doing.**

- [ ] **Boundless Socratic Learning with Language Games**
  > ğŸ“ [\[2411.16905\] Boundless Socratic Learning with Language Games](https://arxiv.org/abs/2411.16905)

- [ ] **Wow, automated reasoning!  From aws?!**
  > ğŸ“ [Prevent factual errors from LLM hallucinations with mathematically sound Automated Reasoning checks (preview) | Amazon Web Services](https://aws.amazon.com/blogs/aws/prevent-factual-errors-from-llm-hallucinations-with-mathematically-sound-automated-reasoning-checks-preview/)

- [ ] **[5 Winning Automated Game Testing Tactics From "Sea of Thieves"](https://modl.ai/automated-game-testing-lessons/)**

- [ ] **[Lovelace Studio (@NyricWorlds) on X](https://x.com/NyricWorlds/status/1866497691884339533?s=19)**
  > ğŸ“ Get on wait list for this!

- [ ] **Watch this eventually.  Story about character ai**
  > ğŸ“ [Daniel - Js Craft (@js_craft_hq) on X](https://x.com/js_craft_hq/status/1869342469705658695?s=19)

- [ ] **Human interaction**
  > ğŸ“ [Jiaman Li (@jiaman01) on X](https://x.com/jiaman01/status/1870003473900810677?s=19)

- [ ] **Wow cool, aws agent orchestration,  in python though,  ugh.  Likely will not use.**
  > ğŸ“ [Sumanth (@Sumanth_077) on X](https://x.com/Sumanth_077/status/1870834042473709572?s=19)

- [ ] **Read this text to sql, hmmm.  Share this with work.**
  ğŸ·ï¸ COMPUTER
  > ğŸ“ [Harrison Chase (@hwchase17) on X](https://x.com/hwchase17/status/1873042087240974366?s=19)

- [ ] **This is what I wanted!!  I could make this website for my agents**
  > ğŸ“ [Yohei (@yoheinakajima) on X](https://x.com/yoheinakajima/status/1873535729424646307?s=19)

    - [ ] **On my list to build something similar for my roblox agents simply for qa purposes, but could be extended for customization, command, and control purposes.   Great stuff!  Would be very interested in contributing depending on your direction and design pattern choices.**

- [ ] **Omg, this is cool,  is like my api.humans think any 10bits a second,  like slow, this is proof I'm on right track**
  > ğŸ“ [Neuroscience News (@NeuroscienceNew) on X](https://x.com/NeuroscienceNew/status/1873834528885923879?s=19)

- [ ] **Meta memory layers?  Memory that scales?**
  > ğŸ“ [James (@AwokeKnowing) on X](https://x.com/AwokeKnowing/status/1874953528231526769?s=19)

- [ ] **How to use reasoning models**
  > ğŸ“ [Carlos E. Perez (@IntuitMachine) on X](https://x.com/IntuitMachine/status/1878753161542041624?s=19)

- [ ] ****Harnessing Language for Coordination: A Framework and Benchmark for LLM-Driven Multi-Agent Control****
  > ğŸ“ [Harnessing Language for Coordination: A Framework and Benchmark for LLM-Driven Multi-Agent Control](https://arxiv.org/abs/2412.11761)

- [ ] **Cool thing about memory**
  > ğŸ“ [Zep Is The New State of the Art In Agent Memory](https://blog.getzep.com/state-of-the-art-agent-memory/)

- [ ] **Holy wtf is this.   Agents make agents...**
  > ğŸ“ [Jeff Clune (@jeffclune) on X](https://x.com/jeffclune/status/1825559340117619041?s=19)

- [ ] **Chain of agents.  Better than rag**
  > ğŸ“ [Chain of Agents: Large language models collaborating on long-context tasks](https://research.google/blog/chain-of-agents-large-language-models-collaborating-on-long-context-tasks/)

- [ ] **Read this.  I replied on X here [Zak Kysar (@ZacharyKysar) on X](https://x.com/ZacharyKysar/status/1897628874072018971?s=19)**
  > ğŸ“ [Sarah DADA X (@SarahDADAX1) on X](https://x.com/SarahDADAX1/status/1894814006243926494?s=19)

- [ ] **Society of consciousness!!   They offer benchmarks.  I need to read some of their papers to see if there are any thoughts on them.**
  > ğŸ“ [Izak Tait (@burnt_jester) on X](https://x.com/burnt_jester/status/1902092522165559510?s=09)

- [ ] **Wait,  I need to read this,  like today. And try the model.  OK thoughts, ugh it only inputs images and language prompt Yada Yada.  I don't need this.    I am after longer term goals and planning,  not this 10hz fine motor movement planning.**
  > ğŸ“ [Jim Fan (@DrJimFan) on X](https://x.com/DrJimFan/status/1902117478496616642?s=19)

- [ ] **Omg what,  llm inside of roblox?!**
  > ğŸ“ [\[Beta\] Introducing Text Generation API](https://devforum.roblox.com/t/beta-introducing-text-generation-api/3556520)

    - [ ] **I could get these back to ayoai eventually.   I still need the server for more external api calls abs navy other reasons.  I think main reason is that we want ayoI to work with other 3d physics engines, so it must stay api based like this.**
    - [ ] **However, we could utilize this for chatting tokens which will save us time.**

- [ ] **Read this in detail.  This is about the openai sdk for creating agents.  Not sure i like the abstraction level though,  ugh.  I don't think i should get distracted by this now though.**
  > ğŸ“ [Adam Silverman (Hiring!) ğŸ–‡ï¸ (@AtomSilverman) on X](https://x.com/AtomSilverman/status/1902403931130749068?s=19)

- [ ] **New competitor here?  Learning like an animal. [AI isn't actually intelligent. IntuiCell already is.](https://intuicell.com/)**
  > ğŸ“ A paper here: [A Foundational Theory for Decentralized Sensory Learning](https://arxiv.org/abs/2503.15130)

    - [ ] **Read the paper.  Reminds me a bit about utility theory.   Maybe I could ask llm to make code that fits what this paper says.   Start out with dating,  summerize this work.   Then say,  options on akimolishing this,  then day build it.**

- [ ] **Shit, who is this competitor inait?!  They partnered with Microsoft.  Hmmm...  [Technology â€” inait](https://www.inait.ai/technology)**
  > ğŸ“ For brain technology.  No papers though.

- [ ] **Fuck, competitor,  this is exactly what i am doing.   read this paper.  This is my odea?!  [Zhongwen Xu (@zhongwen2009) on X](https://x.com/zhongwen2009/status/1900504709359874334?s=19)**
  > ğŸ“ [SOCIAL MEDIA TITLE TAG](https://zhongwen.one/projects/portal/)

- [ ] **This looks super cool.  Entropy, the degree of disorder, forms edges.  Wow, very cool.**
  > ğŸ“ [Self-Organizing Graph Reasoning Evolves into a Critical State for Continuous Discovery Through Structural-Semantic Dynamics](https://arxiv.org/abs/2503.18852)

- [ ] **Intuition, what does that look like?**
  > ğŸ“ [Carlos E. Perez (@IntuitMachine) on X](https://x.com/IntuitMachine/status/1906111749360885978?s=19)

- [ ] **What is this paper!!!  Self-Evolving Multi-Agent Simulations for Realistic Clinical Interactions -  -**
  > ğŸ“ [Self-Evolving Multi-Agent Simulations for Realistic Clinical Interactions](https://arxiv.org/abs/2503.22678)

- [ ] **Whow, wait, how is this being done?!  I need to look at how he set this up,  hmm.  Only like 5 actions available,  hmm.**
  > ğŸ“ [Liang Pan (@liangpan_t) on X](https://x.com/liangpan_t/status/1905981439914721545?s=19)

- [ ] **This is why I think how an adult mind works has little to do with how am adult mind learns.  Meaning, building a brain that can learn like a human may not be my goal.  I think my goal is to build intelligent embodied beings that are better than humans.   Llms are not that though,  they lack being in context, in the world.  Hmmmm**
  > ğŸ“ [Richard Sutton (@RichardSSutton) on X](https://x.com/RichardSSutton/status/1906827723991081101?s=19)

    - [ ] **This is why I want to start from top level principles, and from there can see if the brain could make that happen over time.**
    - [ ] **Called the symbolic end, hmmm**
    > ğŸ“ [Alexander Naumenko (@AlexanderNaume2) on X](https://x.com/AlexanderNaume2/status/1906382770412159421?s=19)

- [ ] **What is dreamer?? Cool stepping stones!**
  > ğŸ“ [Jeff Clune (@jeffclune) on X](https://x.com/jeffclune/status/1907481024818225192?s=19)

- [ ] **Try this on some of my prompts and documentaion.**
  > ğŸ“ [Matt Shumer (@mattshumer_) on X](https://x.com/mattshumer_/status/1909262079799755123?s=19)

- [ ] **This is a free 3d world in three.js!!  Wow**
  > ğŸ“ [Majid Manzarpour (@majidmanzarpour) on X](https://x.com/majidmanzarpour/status/1909810088426021192?s=19)

- [ ] **Difference between llm and human brains**
  > ğŸ“ [elvis (@omarsar0) on X](https://x.com/omarsar0/status/1916542397216960547?s=19)

- [ ] **New planning research paper**
  > ğŸ“ [Rohan Paul (@rohanpaul_ai) on X](https://x.com/rohanpaul_ai/status/1920769209837252759?s=19)

- [ ] **Read this, dinnertime take on intelligence**
  > ğŸ“ [Alexander Naumenko (@AlexanderNaume2) on X](https://x.com/AlexanderNaume2/status/1924120184836542683?s=19)

    - [ ] **[Knut JÃ¤gersberg (@JagersbergKnut) on X](https://x.com/JagersbergKnut/status/1924372958035747120?s=19)**

- [ ] **What did he taking about?  First hint!**
  > ğŸ“ [John Carmack (@ID_AA_Carmack) on X](https://x.com/ID_AA_Carmack/status/1925710474366034326?s=19)

- [ ] **How to reflect... llms**
  > ğŸ“ [nicole summer hsing (@NicoleSHsing) on X](https://x.com/NicoleSHsing/status/1929217404619673873?s=19)

- [ ] **Cool research - there is value/reward based, and then frequency based**
  > ğŸ“ [New Research Reveals the Brain Learns Differently Than We Thought](https://scitechdaily.com/new-research-reveals-the-brain-learns-differently-than-we-thought/)

- [ ] **Altera opened sourced some Minecraft agent!! This is just the open sourced side, not the behavior side.**
  > ğŸ“ [GitHub - FundamentalLabs/minecraft-mcp: MCP server for minecraft](https://github.com/FundamentalLabs/minecraft-mcp)
  
  - [ ] **Why did Jack mention this research about a replacement to alpha evolve or something?**
  > ğŸ“ [Darwin Godel Machine: Open-Ended Evolution of Self-Improving Agents](https://arxiv.org/abs/2505.22954)
  > ğŸ“ [Video breaking down the paper.](https://www.youtube.com/watch?si=nvIwKLTvBndm6DD4&v=cMbGmdy2sfM&feature=youtu.be)
  > ğŸ“ Then that one guy at work mentioned openevolve, which is open source brain of alpha evolve!
  
  
# ğŸ“‹ AyoAi Text-to-World

- [ ] **Holy shit, I need to find a qay to make a rolbox world automatically thorugh an api (or get an agent to do it). Then, hook up to its world and add scripts via the roblox api they offer. Then, after the script, I can install ayoAi, and kick off the behavior creation. All in all, could take three minutes. . .**

- [ ] **Animation controls the arms?  Also here is apubluc dataset of emotions**
  > ğŸ“ [Zhengyi â€œZenâ€ Luo (@zhengyiluo) on X](https://x.com/zhengyiluo/status/1801471798342471987?s=19)

- [ ] **Omg, text to 3d object!  Yet another, he says**
  > ğŸ“ [Dreaming Tulpa ğŸ¥“ğŸ‘‘ (@dreamingtulpa) on X](https://x.com/dreamingtulpa/status/1801892577165070463?s=09)

- [ ] **Umm, what the heck is this.   Text to avitar**
  > ğŸ“ [Dreaming Tulpa ğŸ¥“ğŸ‘‘ (@dreamingtulpa) on X](https://x.com/dreamingtulpa/status/1802670212027760876?s=19)

- [ ] **Holy wtf, mesh anything?! [MeshAnything - a Hugging Face Space by Yiwen-ntu](https://huggingface.co/spaces/Yiwen-ntu/MeshAnything)**
  > ğŸ“ [dylan (@dylan_ebert_) on X](https://x.com/dylan_ebert_/status/1802782676065178024?s=19)

- [ ] **Wait,  what is this?  Roblox launched generative ai?!**
  > ğŸ“ [David Baszucki (@DavidBaszucki) on X](https://x.com/DavidBaszucki/status/1803076830452469977?s=19)

- [ ] **[Vaibhav (VB) Srivastav (@reach_vb) on X](https://x.com/reach_vb/status/1877100242534912068?s=19)**

- [ ] **[MrNeRF (@janusch_patas) on X](https://x.com/janusch_patas/status/1879074236331114748?s=19)**

- [ ] **[Nuno Leiria (@NunoPLeiria) on X](https://x.com/NunoPLeiria/status/1901399092120707503?s=19)**

- [ ] **Read this... damn!!  text to world [Suny Shtedritski (@shtedritski) on X](https://x.com/shtedritski/status/1903112129420443712?s=19)**

- [ ] **Text to minecraft**
  > ğŸ“ [Julian Togelius (@togelius) on X](https://x.com/togelius/status/1904237570483261598?s=19)

- [ ] **Need to fix the behavior tree json schema. It's on the behavior trees the llms make, not the behavior trees robl9x executes- those are two different types of trees for a reason.**
  > ğŸ“ Need to add things like participants. Hmmm

# ğŸ“‹ Interesting Tools

- [ ] **Great article on how to get tensoner flow machined learned model into roblox**
  > ğŸ“ https://devforum.roblox.com/t/machine-learning-in-roblox-with-tensorflow-and-webservers/1298582

- [ ] **What does a transformer mean?  Learn it and see if I need to build it**

    - [ ] **What is a Transformer vs. a gated RNN?**
    > ğŸ“ "Transformers have increasingly outperformed gated RNNs in obtaining new state-of-the-art results on supervised tasks involving text sequences."

- [ ] **PyTorch is a MetaAi based company, that says it is free for experimental stuff.  It looks tempting, but I would not be able to use it long term.  Maybe I should just build something internally, that looks at correlations and call it day.**
  > ğŸ“ [PyTorch](https://ai.facebook.com/tools/pytorch/)
  
  <details>
  <summary>ğŸ’¬ Comments (2)</summary>
  
  **Comment 1:** Just use the book in the model, and start there!?!
  
  **Comment 2:** The model does not need to be that deep if I gather all the data needed and exported the controls. Hmm. I could build hte correlation model in java, super fast and make a fast api and make it free. Start small, right. Maybe I am spending too much time with research these ai models. Hmm.
  
  </details>

- [ ] **Maybe I need to review that AI learning class again,  And review some of the code and see if I can get it working,etc.  Then my feet will be wet with ideas.  I need to do this before I move back to my model.**

- [ ] **Google this:  recurrent networks classification**
  
  <details>
  <summary>ğŸ’¬ Comments (1)</summary>
  
  **Comment 1:** And yikes, Wharton about this way of catahorizing sequences?!  Sequence Classification with LSTM Recurrent Neural Networks in Python with Keras


  
  </details>

- [ ] **best way to explain a neural network classification**
  
  <details>
  <summary>ğŸ’¬ Comments (1)</summary>
  
  **Comment 1:** Cool article here that almost explains how to solve it without using a service:  https://towardsdatascience.com/the-complete-guide-to-neural-networks-multinomial-classification-4fe88bde7839
  
  </details>

- [ ] **Dang, this game AI from black and white looks super cool!!!**
  > ğŸ“ https://www.cs.rochester.edu/~brown/242/assts/termprojs/games.pdf
  
  <details>
  <summary>ğŸ’¬ Comments (7)</summary>
  
  **Comment 1:** This idea of a planner would make creatures much more powerful.
Instead of giving creatures one command at a time and having to wait for that
task to be completed to give the creature another command, the user could
simply create a list of goals that it wishes for the creature to complete [3].
Individual goals could be given importance values that give the creature an idea
of what goals should be more immediately met. In addition to listing goals and
importance, the user could specify a specific search function and search limit so
that the planner doesn't waste too many cycles chasing after impossible goal
states. Once all the goal state information is listed the planner could run in the background and upon completion return the best sequence of actions that satisfy
the user's needs. This list could then be sent from the user to the creature so
that the creature could get to work on its newly created plan of actions. A
planner would give the user more time to spend helping its villagers or doing
missions since its creature could be given a plan that may take a considerable
amount of time and accomplish many tasks. Of course, there would have to be
restrictions in the actions that the planner can give to the creature. Otherwise the
user could give the creature a list of actions that may train the creature very
efficiently and that would take the fun and challenge out of having to manually
train and nurture one's creature. One possible solution is that the planner could
be a special tool that is only unlocked once a user's creature has reached a
certain intelligence level
  
  **Comment 2:** In his review of the AI system he created for â€œBlack and Whiteâ€, Richard
Evans writes, â€œA decision tree is built by looking at the attributes which best
divide the learning episodes into groups with similar feedback values. The best
decision tree is the one that minimizes entropy, a measure of how disordered the
feedbacks are. The algorithm used to dynamically construct decision-trees to
minimize entropy is based on (Ross) Quinlanâ€™s ID3 system.â€ [4]
  
  **Comment 3:** it does not yet know what type of object satisfies its hunger best. It may see a
fence and instantly walk over and take a bite out of it. It will then realize that the
fence did not satisfy its hunger well and tasted horrible in the process. The
creature will alter its internal food decision tree as to keep it from eating fences in
the future [14].
  
  **Comment 4:** After a creature completes an
action to satisfy a certain desire it will look at how well that desire was satisfied
and adjust its internal weight structure accordingly [4].
  
  **Comment 5:** This method is used alongside with rules-based AI (situational calculus) to give
creatures their basic intelligence about objects. This scripted-AI is the most
popular form of artificial intelligence found in games today [2]. Decision trees
represent agentsâ€™ beliefs about general types of objects. Finally, neural networks
of perceptrons represent desires [5].
  
  **Comment 6:** Strength of obstructions to walking:
object.man-made.fence->1.0
object.natural.body-of-water.shallow-river->0.5
object.natural.rock->0.1
  
  **Comment 7:** Markie pointed me to this one
  
  </details>

- [ ] **Notes on white board**
  
  <details>
  <summary>ğŸ’¬ Comments (2)</summary>
  
  **Comment 1:** Took that photo on Nov 8 because stated to learn stomp lol.  I think I have all those notes down, I need to confirm. 
  
  **Comment 2:** 
  
  </details>

- [ ] **[Reinforcement Learning : Markov-Decision Process (Part 1) | by blackburn | Towards Data Science](https://towardsdatascience.com/introduction-to-reinforcement-learning-markov-decision-process-44c533ebf8da)**

- [ ] **Link to someone running 1000 npcs and a video**
  > ğŸ“ https://devforum.roblox.com/t/achieving-mass-npc-count/263949

- [ ] **Who is this?**
  > ğŸ“ [GitHub - ivyraine/agentcraft: AI Agent Simulation generates Minecraft Settlements](https://github.com/ivyraine/agentcraft)

- [ ] **Awesome take from tesla**
  > ğŸ“ Idealism is the main atecedant?!
  
  <details>
  <summary>ğŸ’¬ Comments (1)</summary>
  
  **Comment 1:** Nikola Tesla Explains His Philosophy On Life

â€œWe are all automatons,â€ he reflected, â€œobeying external influences. We are entirely under the control of agents that beat on our senses from all directions of the outside world. Being merely receivers from the outside, it is a very important question how good the receivers are - some are sensitive and receive accurately. Others are sluggish and their reception is blurred. The individual who is a better machine has so much greater chance of achieving success and happiness. An individual who is an offender of law is a machine in which one or another organ has been deranged, so that the responses are no longer accurate.

â€œThere is no chance in nature, although the modern theory of indeterminacy attempts to show scientifically that events are governed by chance. I positively deny that. The causes and effects, however complex, are intimately linked, and the result of all inferences must be inevitably fixed as by a mathematical formula.

â€œI also absolutely deny the existence of individuality. It took me not less than twenty years to develop a faculty to trace every thought or act of mine to an external influence. We are just waves in time and space, changing continuously, and the illusion of individuality is produced through the concatenation of the rapidly succeeding phases of existence. What we define as likeness is merely the result of the symmetrical arrangement of molecules which compose our body.â€

Says There Is No Soul

â€œHow about the soul - the spirit?â€ he was asked.

â€œAh,â€ he exclaimed, â€œbut there is no soul or spirit. These are merely expressions of the functions of the body. These life functions cease with death and so do soul and spirit.

â€œWhat humanity needs is ideals. Idealism is the force that will free us from material fetters.â€

("Tesla Seeks to Send Power to Planets." New York Times, July 11th, 1931.)

Dr. Nikola Tesla. ğŸ§”ğŸ»â€â™‚ï¸â¤ï¸ğŸŒ
  
  </details>

- [ ] **Julian Togelius is an Associate Professor of Computer Science and Engineering at NYU, and Cofounder and research director at modl.ai**
  > ğŸ“ [â€TalkRL: The Reinforcement Learning Podcast: Julian Togelius on Apple Podcasts](https://podcasts.apple.com/us/podcast/julian-togelius/id1478198107?i=1000622243973)
  
  <details>
  <summary>ğŸ’¬ Comments (9)</summary>
  
  **Comment 1:** Other things happening in rl?  Dreamer.  Offline q learning to work well is boring interesting.   The things that team does to work well is simple. Sevra Laveen?  Quality diversity algorithm in rl, is where he goes looking.
  
  **Comment 2:** Open ended learning.  His heart still beats for revolutionary algoythems.
  
  **Comment 3:** We need reinforcement learning foundation models that can generalize.  Rl is brittle to a color scheme and other things,  how to get rid of the brittlness?
  
  **Comment 4:** He wants rl models to go the way of llms, where you ever aprompt, and the model is open sourced 
  
  **Comment 5:** Both Jack's space and dreamer version three do vecterizations of environments.   What is that?  What is a vectorization of an environment?
  
  **Comment 6:** Dreamer version 3, that can be more efficient at getting to high performance. 
  
  **Comment 7:** Jacks space rl that can do the rl loop much faster?  This will allow us to train faster
  
  **Comment 8:** Choose your weapon, survival techniques for depressed academics
  
  **Comment 9:** Open ended learning.  The other one I listened to was about multi model.  Abs they have to communicate 
  
  </details>

- [ ] **Jakob Foerster on Multi-Agent learning, Cooperation vs Competition, Emergent Communication, Zero-shot coordination, Opponent Shaping, agents for Hanabi and Prisoner's Dilemma, and more.**
  > ğŸ“ [â€TalkRL: The Reinforcement Learning Podcast: Julian Togelius on Apple Podcasts](https://podcasts.apple.com/us/podcast/julian-togelius/id1478198107?i=1000622243973)
  
  <details>
  <summary>ğŸ’¬ Comments (18)</summary>
  
  **Comment 1:** big question is how can we replace the need for data with simulation and methods that
improve themselves in simulation and this is a big sort of again going back to one of the blind
spots right if we're thinking this this to the to the end the current the current hype train
right what is the final stop of this hype train and what what happens next so i heard some of
  
  **Comment 2:** Jacob Beck and
rest of Wario recently presenting their their meta RL survey paper and so and so I wanted to see
you wanted to hear how how you you relate that to to meta RL so meta self-play that is a phrase that
I have not heard before is that a new thing with and are you are you quoting a phrase here in your
  
  **Comment 3:** Meta reinforcement learning, 44:30
  
  **Comment 4:** meta RL survey paper and so and so I wanted to see
you wanted to hear how how you you relate that to to meta RL so meta self-play that is a phrase that
I have not heard before is that a new thing with and are you are you quoting a phrase here in your
  
  **Comment 5:** Meta fucking self-play....  that's me
  
  **Comment 6:** because based on my and your last policy the learning algorithm in the other agent is going
to induce a state transition a new policy that comes due to the learning process so this is
meta reinforcement learning in a specific setting and more interestingly we get to meta self-play
which is when we combine two mforce agents that learn to shape another shaper so shaping is again
useful opponent shaping here right you have a learning you have a learning agent something
like a ppo agent that's maximizing its own return doing essentially independent learning in the
prison's dilemma and there were meta learning another ppo agent that can learn to optimally
  
  **Comment 7:** Shape another shaper....
  
  **Comment 8:** player's learning step
learning step okay learning step this is it this is the crucial part because how they affect the
policies the current policies that's really done by rl right reinforcement learning gives me time
horizons i can just play a thousand times samples until the end of the episode i see how my action
change you have change impact your future actions i like your policy but the big thing is if you
and i are learning agents then these trajectories generated will go into your learning algorithm
right so imagine you have wayment you have tesla these cars are on the road
  
  **Comment 9:** mutual affection become quite likely and this has been a focus of of this this line of work
how do we do machine learning when our decisions are influencing other learning systems in the long
run and it's all the unbelievable opponent shaping and i'm happy to talk more about any of the
recent papers or methods in that space so you're talking about policies that are choosing actions
policies that are choosing actions based on how they will affect the other player's policy in
future is that is that what you're getting to how they will affect the other player's learning step
learning step okay learning step this is it this is the crucial part because how they affect the
policies the current policies that's really done by rl right reinforcement learning gives me time
horizons i can just play a thousand times samples until the end of the episode i see how my action
  
  **Comment 10:** we would like to have agents that can actually account for the fact that other players are there
and are learning and realize that by reward and punishment they can shape them into cooperation
and that was the key insight behind Lola where we don't maximize don't take a gradient step towards
increasing my current return assuming the other agent's policy is fixed but we differentiate
through the learning step of the opponent in the environment anticipating that our actions will go
into their training data and i will never forget when we first implemented this method this would
do my internship at openai first implementation first run and we get this policy out that
cooperates but it doesn't cooperate blindly it placed it for tat this moment is always going
to be something that i remember in my research career because it was a hard problem we had
honest we had come up with a theory of what is driving the the failure of current methods
and we managed to fix it now lola has obvious issues it's asymmetric it assumes that the other
agents are naive learners it's myopic it only shapes one time step and requires these higher
order derivatives and ever since in particular
  
  **Comment 11:** Said opponent shaping is 
  
  **Comment 12:** hout looking at your hand then suddenly all you know is this card is red because that's
revealed by the environment but you have no idea about why I said this because I would have said
this randomly anyway and that's the main idea of belief of belief learning it really mathematically
this method takes away the risk or the ability of having emergent protocols in multi-agent systems
but don't we need some type of conventions in Hanabi for example if you hint this card is a one I
should probably assume that you're telling me this because the card is playable even if it's
not obvious from the current state of the board and you can get this out by iterating off belief
learning in hierarchies and then you get extremely human compatible gameplay out of OBL and at this
point if you're listening to the podcast I highly recommend to check out our demo of off belief
learning if you're interested and this is at bit.ly and then slash OBL minus demo and you can
actually play with these OBL bots and these are really interesting to play with at least for me
that was quite fascinating to see how Hanabi looks 
  
  **Comment 13:** Off believe learning, obl.  They must agree on a communication protocol.   Like,  when sometime sends a red card,  that may mean something else to another person.   Like, red only means x, never y
  
  **Comment 14:** I wanted to have developed our algorithms that get to this more
sensible way of playing of acting in these tech POMDPs is part observable fully cooperative systems
without requiring vast amounts of human data and the last instance of this is called off-belief
learning which was sort of looking back one of the papers that I've really enjoyed working on
that to me addressed a lot of open questions but it's also paper that's notoriously hard to make
sense of
  
  **Comment 15:** I've used the card
game Hanabi here for the last few years really to develop novel methods in that space
  
  **Comment 16:** A good lever game. 10 levers, one is worth 1, another is worth .9.  But you only get 1 if you both pick it.   Something like this is a good test.   Listen to this test again. Around 20 minutes. 
  
  **Comment 17:** So to put this into one sentence, the problem of multi-agent learning is non-stationarity
and equilibrium selection.
  
  **Comment 18:** So, for example, if you're looking at the world from the perspective of one agent, then
suddenly the actions that other agents take will change the environment that's being faced
by that agent.
And that's called non-stationarity.
  
  </details>

- [ ] **Llm haystack?!**
  > ğŸ“ [Introducing Agents in Haystack: Make LLMs resolve complex tasks | Haystack](https://haystack.deepset.ai/blog/introducing-haystack-agents)

- [ ] **Agents new paper - this is an open source agent I could lok into using? Code is there, with planning and all?? Hmm. . .**
  > ğŸ“ [Paper page - Agents: An Open-source Framework for Autonomous Language Agents](https://huggingface.co/papers/2309.07870)

- [ ] **[Exploring LLMs and AI Education with Luis Serrano - The What's AI Episode Podcast 15](https://youtu.be/NoyQKKQdI0M?si=f6ihshsfau7FWpCv)**
  > ğŸ“ This has fog resources to watch,  like llm University and cohere

- [ ] **[Introduction to Language Models (LLM's, Prompt Engineering, Encoder/Decoder and more)](https://youtu.be/9PGmMdkTZls?si=dpYdRX-K47E0Rfrh)**

- [ ] **Holy shit a 5 hour course?!**
  > ğŸ“ [Create a Large Language Model from Scratch with Python â€“ Tutorial](https://youtu.be/UU1WVnMk4E8?si=sHDq6KPYCiiaA9Mu)

- [ ] **[LLM Foundations (LLM Bootcamp)](https://youtu.be/MyFrMFab6bo?si=r4hPRVoBc3FhBgKu)**

- [ ] **How to edit an encoder?  Llm?**
  > ğŸ“ Next podcast to listen to

- [ ] **What is this? **Cellular Automata?****
  > ğŸ“ https://developmentalsystems.org/sensorimotor-lenia/

    - [ ] **And this: **Flow-Lenia: Towards open-ended evolution in cellular automata through mass conservation and parameter localization****
    > ğŸ“ [hardmaru on X](https://twitter.com/hardmaru/status/1716019268205322508?s=19)

- [ ] **How to drive the browser.**
  > ğŸ“ [GitHub - nat/natbot: Drive a browser with GPT-3](https://github.com/nat/natbot)

- [ ] **What is this?**
  > ğŸ“ [christmas - Wolfram|Alpha](https://www.wolframalpha.com/input?i=christmas&assumption=%7B%22DPClash%22%2C+%22HolidayE%22%2C+%22christmas%22%7D+-%3E+%7B%7B%22ChristmasDay%22%2C+%22Christianity%22%7D%2C+%22dflt%22%7D&assumption=%7B%22C%22%2C+%22christmas%22%7D+-%3E+%7B%22Holiday%22%2C+%22dflt%22%7D&assumption=%7B%22HolidayYear%22%2C+%7B%22ChristmasDay%22%2C+%22Christianity%22%7D%7D+-%3E+%222023%22)

- [ ] **Try to read this today before I give up?**
  > ğŸ“ [Deep Reinforcement Learning: Pong from Pixels](http://karpathy.github.io/2016/05/31/rl/)

- [ ] **Get familiar with how LLMs work**

    - [ ] **What is the difference between vectorize and embeddings**
    - [ ] **Wait, how do I use the instruction tuned ones?**

      - [ ] **Wait what is this?  The instruct model?  Hmmm**
      > ğŸ“ [mistralai/Mistral-7B-Instruct-v0.1 Â· Hugging Face](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1)
    - [ ] **Read this about fine tuning....**
    > ğŸ“ [anton (@abacaj) on X](https://twitter.com/abacaj/status/1729889359040819474?s=19)
    - [ ] **Read this blog?**
    > ğŸ“ [Teach Llamas to Talk: Recent Progress in Instruction Tuning](https://gaotianyu.xyz/blog/2023/11/30/instruction-tuning/)
    - [ ] **Find out what a knoldge graph + llm is before I build a behavior tree + llm**
    - [ ] **Faster inference with powerline?**
    > ğŸ“ [Meet PowerInfer: A Fast Large Language Model (LLM) on a Single Consumer-Grade GPU that Speeds up Machine Learning Model Inference By 11 Times](https://www.marktechpost.com/2023/12/23/meet-powerinfer-a-fast-large-language-model-llm-on-a-single-consumer-grade-gpu-that-speeds-up-machine-learning-model-inference-by-11-times/)
    - [ ] **Llm plan?  A planner for any agent**
    > ğŸ“ [Jerry Liu (@jerryjliu0) on X](https://twitter.com/jerryjliu0/status/1740778991064408450?s=19)
    - [ ] **Json structured output?!!!**
    > ğŸ“ [Structured Outputs with Anyscale and Zod - Instructor (JS)](https://jxnl.github.io/instructor-js/blog/2024/01/01/patching/)
    - [ ] **Super small llm!**
    > ğŸ“ https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/
    - [ ] **Anther small llm here.   Yes, I need to use these to edit my descriptions and such**
    > ğŸ“ [AK (@_akhaliq) on X](https://twitter.com/_akhaliq/status/1748533176547369391?s=19)

- [ ] **This looks like an interesting book on rl.**
  > ğŸ“ [Stefano Albrecht (UoE Agents Group) (@UoE_Agents) on X](https://twitter.com/UoE_Agents/status/1731665070357107066?s=19)

- [ ] **Omg, myself was on this, but after he spoke, there is free coffee where they used bedrock to fine tune llama!!!  I want that so bad,  let's fucking go**
  > ğŸ“ [AWS re:Invent 2023 - Customize FMs for generative AI applications with Amazon Bedrock (AIM247)](https://youtu.be/YY9N7sDoP30?si=xtuDlntSW2nA0WsB)

- [ ] **Read this on desktop to help visualize an llm**
  > ğŸ“ [MatthewBerman (@MatthewBerman) on X](https://x.com/MatthewBerman/status/1731800405036896348?s=09)

- [ ] **Java for llms?  I downloaded it**
  > ğŸ“ [Java and LLMs: are we there yet?](https://medium.com/@mpapadimitriou92/java-and-llms-are-we-there-yet-300cf9418ed7)

- [ ] **Always output json?**
  > ğŸ“ https://twitter.com/jxnlco/status/1743305057645334979?s=19

- [ ] **Try github copilot library for python?!!  Or is it coursor?**

- [ ] **What is gradio, from Mrigank, it's like a streamlit thing?**

- [ ] **Omg, a wrapper around Llms for filling in json, which saves on tokens?**
  > ğŸ“ [Rohan Paul (@rohanpaul_ai) on X](https://twitter.com/rohanpaul_ai/status/1748896116731683171?s=19)

- [ ] **Research I used to build these behavior trees ... best one below I think**
  > ğŸ“ [GitHub - hms-junk/behaviortree.rbxlua: a simple behaviour tree library for roblox lua ported from a lua library ported from javascript](https://github.com/hms-junk/behaviortree.rbxlua)

    - [ ] **This is a cool one, and has some awesome examples. I need to reread about this stack thing. . .**
    > ğŸ“ [Behavior trees for AI: How they work](https://www.gamedeveloper.com/programming/behavior-trees-for-ai-how-they-work)
    - [ ] **Need to add a parrellel conductor in a behavior tree. Also need to add a stack? And add a repeater. . .**
    - [ ] **Should I be using this one instead?!!?!? [GitHub - Defaultio/BehaviorTree3: An optimized rewrite of BehaviorTree](https://github.com/Defaultio/BehaviorTree3)**
    - [ ] **There is a little more description here. THis is the js implementation of the the thing I was working on.  This has json example!!**
    ğŸ”µ Low
    > ğŸ“ [GitHub - Calamari/BehaviorTree.js: An JavaScript implementation of Behavior Trees.](https://github.com/Calamari/BehaviorTree.js)
    - [ ] **interesting articles but not meaty**

      - [ ] **I like this tree basics, and it sets up a game for me to try . . . from ground up. This is the droids example I built in java. This one accepts variables and should think about that.**
      > ğŸ“ [Game AI â€“ An Introduction to Behaviour Trees](https://www.javacodegeeks.com/2014/08/game-ai-an-introduction-to-behaviour-trees.html)
      - [ ] **Dang, this one looks awesome, this is java code I like better I think. Link does not work anymore?**
      > ğŸ“ [GitHub - paasovaara/behavior-trees: Simple behavior-tree implementation](https://github.com/paasovaara/behavior-trees)
      - [ ] **[Behavior Trees by Example. AI in an Android game.](https://magicscrollsofcode.blogspot.com/2010/12/behavior-trees-by-example-ai-in-android.html?m=1)**
    - [ ] **I really like this video. I like it for a few reasons. One, is that it describe a way to use events to stop working on something and validate everything in the tree, else evaluate each second. I Am going to need this because a thing can get stuck in a tree. . . I can evaluate this tree in ayoai and not in roblox though, right? Also, I like the enticer concept they had? Also I like that they said every sigle task node followed the same outline. an on enter, on exit, and conditions on top.**
    > ğŸ“ [Behavior Trees: Three Ways of Cultivating Strong AI](https://www.gdcvault.com/play/1012416/Behavior-Trees-Three-Ways-of)
    - [ ] **Omg... parameterizing behavior trees**
    > ğŸ“ Parameterizing Behavior Trees https://people.cs.umass.edu/~fmgarcia/Papers/Parameterizing%20Behavior%20Trees.pdf

- [ ] **Ohh, I need to read this (and read game dev stacks again)**
  > ğŸ“ [The Craft of Behavior Trees](https://medium.com/@sion_denis/the-craft-of-behavior-trees-ab6b181ce21a)

- [ ] **Github to file?!**
  ğŸ·ï¸ EVENING
  > ğŸ“ [Eric Hartford (@erhartford) on X](https://twitter.com/erhartford/status/1767284737788514724?s=19)

- [ ] **Wow what is this?!  Meta gpt?**
  ğŸ·ï¸ EVENING
  > ğŸ“ [MetaGPT (@MetaGPT_) on X](https://twitter.com/MetaGPT_/status/1767965444579692832?s=19)

- [ ] **Wow, here is an awesome set of domain files: [GitHub - AI-Planning/pddl-generators: A collection of PDDL generators, some of which have been used to generate benchmarks for the International Planning Competition (IPC).](https://github.com/AI-Planning/pddl-generators)**

- [ ] **Pddl wiki?!  Supper cool ayo**
  > ğŸ“ [PDDL+ Domain](https://planning.wiki/ref/pddlplus/domain#processes)

- [ ] **Wow, code to force structured output.  I like**
  > ğŸ“ [Lance Martin (@RLanceMartin) on X](https://twitter.com/RLanceMartin/status/1776015679478767698?s=19)

- [ ] **Anthropic tool use**
  > ğŸ“ [Tool use (function calling)](https://docs.anthropic.com/claude/docs/tool-use)

- [ ] **Interesting how to force json**
  > ğŸ“ [Alex (@alexalbert__) on X](https://twitter.com/alexalbert__/status/1778139303639654709?s=19)

- [ ] **Learning Vert.x!!**
  > ğŸ“ Yeah

    - [ ] **You canâ€™t do much in Vert.x-land unless you can communicate with a **Vertx object**.  Vertx vertx = Vertx.vertx();**
    > ğŸ“ Most applications will only need a single Vert.x instance, but itâ€™s possible to create multiple Vert.x instances if you require, for example, isolation between the event bus
    - [ ] **You handle events by providing **handlers** to the Vert.x APIs.**
    - [ ] ****Reactor Pattern** In most cases Vert.x calls your handlers using a thread called an **event loop**. As nothing in Vert.x or your application blocks, the event loop can merrily run around delivering events to different handlers in succession as they arrive.  Because nothing blocks, an event loop can potentially deliver huge amounts of events in a short amount of time. For example a single event loop can handle many thousands of HTTP requests very quickly.**

      - [ ] **Vert.x works differently here. Instead of a single event loop, each Vertx instance maintains several event loops. By default we choose the number based on the number of available cores on the machine, but this can be overridden. This means a single Vertx process can scale across your server, unlike Node.js. We call this pattern the **Multi-Reactor Pattern** to distinguish it from the single threaded reactor pattern.**
      - [ ] **Even though a Vertx instance maintains multiple event loops, any particular handler will never be executed concurrently, and in most cases (with the exception of worker verticles) will always be called using the exact same event loop.**
    - [ ] ****Verticles** Vert.x comes with a simple, scalable,Â actor-likeÂ deployment and concurrency model out of the box that you can use to save you writing your own. This model is entirely optional and Vert.x does not force you to create your applications in this way if you donâ€™t want to. The model does not claim to be a strict actor-model implementation, but it does share similarities especially with respect to concurrency, scaling and deployment.**

      - [ ] **Offload to **Worker Verticles**: If the blocking operation is inherently long-running, consider offloading it to a dedicated worker verticle. Worker verticles are designed to handle blocking operations and don't use the main event loop threads.**
      - [ ] **An application would typically be composed of many verticle instances running in the same Vert.x instance at the same time. The different verticle instances communicate with each other by sending messages on the **event bus****
      - [ ] **Normally you would override the start method like in the example above. -  - When Vert.x deploys the verticle it will call the start method, and when the method has completed the verticle will be considered started. -  - You can also optionally override the stop method. This will be called by Vert.x when the verticle is undeployed and when the method has completed the verticle will be considered stopped.**
      - [ ] ****Standard Verticles** These are the most common and useful type - they are always executed using an event loop thread. Weâ€™ll discuss this more in the next section. **Worker Verticles** These run using a thread from the worker pool. An instance is never executed concurrently by more than one thread.**
      - [ ] **Waiting for deployment to complete - Verticle deployment is asynchronous and may complete some time after the call to deploy has returned. -  - If you want to be notified when deployment is complete you can deploy specifying a completion handler:**
      - [ ] **Specifying number of verticle instances - When deploying a verticle using a verticle name, you can specify the number of verticle instances that you want to deploy:**
    - [ ] **Any asynchronous method returns a **Future** object for the result of the call: a success or a failure. You cannot interact directly with the result of a future, instead you need to set a handler that will be called when the future completes and the result is available, like any other kind of event.**

      - [ ] ****Future composition** - compose can be used for chaining futures: when the current future succeeds, apply the given function, that returns a future. When this returned future completes, the composition succeeds.  when the current future fails, the composition fails. Beyond this,Â FutureÂ offers more:Â map,Â recover,Â otherwise,Â andThenÂ and even aÂ flatMapÂ which is an alias ofÂ compose**
    - [ ] ****Context** object - When Vert.x provides an event to a handler or calls the start or stop methods of a Verticle , the execution is associated with a Context. Usually a context is an event-loop context and is tied to a specific event loop thread. So executions for that context always occur on that exact same event loop thread. In the case of worker verticles and running inline blocking code a worker con. will be associated with the execution which will use a thread from the worker thread pool.**
    - [ ] ****Local maps** - Local maps -  allow you to share data safely between different event loops (e.g. different verticles) in the same Vert.x instance.**
    - [ ] ****Json** Unlike some other languages, Java does not have first class support forÂ JSONÂ so we provide two classes to make handling JSON in your Vert.x applications a bit easier.**

      - [ ] **JSON arrays - The  - JsonArray -  class represents JSON arrays. -  - A JSON array is a sequence of values (string, number, boolean). -  - JSON arrays can also contain null values.**
      - [ ] **JSON objects - The  - JsonObject -  class represents JSON objects. -  - A JSON object is basically just a map which has string keys and values can be of one of the JSON supported types (string, number, boolean). -  - JSON objects also support null values.**
    - [ ] ****Buffers** Most data is shuffled around inside Vert.x using buffers.  A buffer is a sequence of zero or more bytes that can read from or written to and which expands automatically as necessary to accommodate any bytes written to it. You can perhaps think of a buffer as smart byte array.**
    - [ ] **Using the **file system** with Vert.x - The Vert.x  - FileSystem -  object provides many operations for manipulating the file system. -  - There is one file system object per Vert.x instance, and you obtain it with  - fileSystem - .**
    - [ ] **What is a steam?  I think this is an api stream?  Like stream the tokens to the page slowly or singing like that?**
    - [ ] ****Json Parser** - You can easily parse JSON structures but that requires to provide the JSON content at once, but it may not be convenient when you need to parse very large structures. -  - The non-blocking JSON parser is an event driven parser able to deal with very large structures. It transforms a sequence of input buffer to a sequence of JSON parse events.**
    - [ ] ****Blocking** you canâ€™t call blocking operations directly from an event loop, as that would prevent it from doing any other useful work. So how can you do this? -  - Itâ€™s done by callingÂ executeBlockingÂ with blocking code to execute, as return you get a future completed with the result of the blocking code execution. -  -**

      - [ ] **Do not block the loop!  If your application is not responsive it might be a sign that you are blocking an event loop somewhere. To help you diagnose such issues, Vert.x will automatically log warnings if it detects an event loop hasnâ€™t returned for some time. If you see warnings like these in your logs, then you should investigate.  If you want to turn off these warnings or change the settings, you can do that in theÂ VertxOptionsÂ object before creating the Vertx object.**
      - [ ] **An alternative way to run blocking code is to use a worker verticle**
      - [ ] **A worker verticle is always executed with a thread from the worker pool. -  - By default blocking code is executed on the Vert.x worker pool, configured with  - setWorkerPoolSize - . -  - Additional pools can be created for different purposes:**
    - [ ] ****security** If writing a web application itâ€™s highly recommended that you use Vert.x-Web instead of Vert.x core directly for serving resources and handling file uploads. -  - Vert.x-Web normalises the path in requests to prevent malicious clients from crafting URLs to access resources outside of the web root. -  - Similarly for file uploads Vert.x-Web provides functionality for uploading to a known place on disk and does not rely on the filename provided by the client in the upload**
    - [ ] ****Event Bus** - The  - event bus -  is the nervous system of Vert.x. -  - There is a single event bus instance for every Vert.x instance and it is obtained using the method  - eventBus - . -  - The event bus allows different parts of your application to communicate with each other, irrespective of what language they are written in, and whether theyâ€™re in the same Vert.x instance, or in a different Vert.x instance.**

      - [ ] **The event bus API is very simple. It basically involves registering handlers, unregistering handlers and sending and publishing messages.**
      - [ ] **Vert.x doesnâ€™t bother with any fancy addressing schemes. In Vert.x an address is simply a string. Any string is valid. However, it is wise to use some kind of scheme, e.g. using periods to demarcate a namespace. -  - Some examples of valid addresses are europe.news.feed1, acme.games.pacman, sausages, and X.**
      - [ ] **Handlers - Messages are received by handlers. You register a handler at an address. -  - Many different handlers can be registered at the same address. -  - A single handler can be registered at many different addresses.**
      - [ ] **Publish / subscribe messaging - The event bus supports publishing messages. -  - Messages are published to an address. Publishing means delivering the message to all handlers that are registered at that address. -  - This is the familiar publish/subscribe messaging pattern.**
      - [ ] **Best-effort delivery - Vert.x does its best to deliver messages and wonâ€™t consciously throw them away. This is called best-effort delivery. -  - However, in case of failure of all or parts of the event bus, there is a possibility messages might be lost. -  - If your application cares about lost messages, you should code your handlers to be idempotent, and your senders to retry after recovery.**

- [ ] **Knowledge graph code?!**
  > ğŸ“ [Yohei (@yoheinakajima) on X](https://twitter.com/yoheinakajima/status/1786055928284127292?s=19)

- [ ] **Gemini flash has free finetunning?**

- [ ] **Chatting with Zak's Survey Paper**

    - [ ] **Questions so far**

      - [ ] **"High level thoughts" are my thoughts so far.Â  Would be interesting to ask the llm to use those and summarize a task list for me?Â  Or ideas from it.**
      - [ ] **Start off with suggested pseudo code, and ask if it looks ok to accomplish . . .**
      - [ ] **Make definition of what the goal is.Â  Like a good.**
      - [ ] **Read through the document, and where you feel confident to answer the open questions, please do so.**
      - [ ] **Read through the document, and go visit every page.Â  If it is a arxiv page, traverse to the â€œview pdfâ€ link, and fully review the pdf.Â  Also, refer to the pdfâ€™s references, and go read those too.Â  Once you see and read everything in full, begin to answer this question:**
      - [ ] **How is Zak, and what do you think he is trying to build?**
      - [ ] **I could add the pseudo code here too?Â  Then ask what it thinks about it.**
      - [ ] **Prompt:  given the pdf, what "method" would you choose for reflection and refinement.  Or,  for memory.  So once I hit my level buckets,  abs the processes in those buckets,  we can finalize the methods.**
    - [ ] **Can be found at this link:**
    - [ ] **Wait,  I like these prompts too chat with my paper  ...  and the repos that these papers share?**
    > ğŸ“ [Deedy (@deedydas) on X](https://x.com/deedydas/status/1802529105860252129?s=19)

- [ ] **Prompt notes**
  > ğŸ“ [Ilya Sutskever (Parody) (@ilyasutsk) on X](https://x.com/ilyasutsk/status/1832211266129293618?s=19)

- [ ] **Clone any website?!  [MatthewBerman (@MatthewBerman) on X](https://x.com/MatthewBerman/status/1886084141025824886?s=19)**

- [ ] **Make text into an image.  The text that uses slashes and stuff to make art.  Put this on top of each of my java files...**
  > ğŸ“ https://codepen.io/Mikhail-Bespalov/pen/JoPqYrz

- [ ] **[Hereâ€™s how I use LLMs to help me write code](https://simonwillison.net/2025/Mar/11/using-llms-for-code/)**
  > ğŸ“ Read how to code with llms here.  This could save me time.  Already read it March 18 2025

- [ ] **Try this agent out instead of openai?!  This was Jens idea!!  The tasks seem easy to automate. [Charly Wargnier (@DataChaz) on X](https://x.com/DataChaz/status/1900189310256853124?s=19)**

- [ ] **Wow, list of free apis!!**
  > ğŸ“ [GitHub - public-apis/public-apis: A collective list of free APIs](https://github.com/public-apis/public-apis)

- [ ] **These guys may be building the same thing I'm building, damn!!**
  > ğŸ“ [@levelsio (@levelsio) on X](https://x.com/levelsio/status/1901963649930928177?s=19)

- [ ] **Wait, so this tool, https://www.epicgames.com/site/en-US/news/loci-is-now-a-part-of-epic-games, it makes meta data fur 3d objects.  Huh, hell yeah.   That is kind of what we need,  no?!**

- [ ] **What is this agent to agent thing?**
  > ğŸ“ [Dan Mac (@daniel_mac8) on X](https://x.com/daniel_mac8/status/1909981379129135305?s=19)

- [ ] **Letta , statefill llm seems cool!!**
  > ğŸ“ [Letta](https://www.letta.com/)

    - [ ] **[Tom DÃ¶rr (@tom_doerr) on X](https://x.com/tom_doerr/status/1910893898349551965?s=19)**
    - [ ] **Letta (formerly MemGPT) is the stateful agents framework with memory, reasoning, and context management.**

- [ ] **Github llm converter**
  > ğŸ“ [Matt Shumer (@mattshumer_) on X](https://x.com/mattshumer_/status/1913282296557224431?s=19)

- [ ] **Read this from nous research, new research [Nous Research (@NousResearch) on X](https://x.com/NousResearch/status/1917299865060794484?s=19)**
  ğŸ·ï¸ COMPUTER
  > ğŸ“ Like, I could hook up my environment to their environment and train something?   What are the other other llms, like the maze?

- [ ] **Omg, claude and code?!  Read this:  [GitHub Actions - Anthropic](https://docs.anthropic.com/en/docs/claude-code/github-actions)**

- [ ] **I left off at page 31, I still like the quote on first page the best.**
  > ğŸ“ [Rick Rubin | The Way of Code: The Timeless Art of Vibe Coding](https://wayofcode.com/#31)

- [ ] **Turn any api into a mcp server!**
  > ğŸ“ [Santiago (@svpino) on X](https://x.com/svpino/status/1927323347760603138?s=19)

- [ ] **Google stick can make uis?!  Mmmmm**
  > ğŸ“ [Everyoneâ€™s looking to get in on vibe coding â€” and Google is no different with Stitch, its follow-up to Jules](https://venturebeat.com/ai/everyones-looking-to-get-in-on-vibe-coding-and-google-is-no-different-with-stitch-its-follow-up-to-jules/)

- [ ] **Visualize github as a graph**
  > ğŸ“ [Charly Wargnier (@DataChaz) on X](https://x.com/DataChaz/status/1928367291890098337?s=19)

- [ ] **Try this to improve prompt**
  > ğŸ“ [Meera | AI Tools & News (@MeeraAIIT) on X](https://x.com/MeeraAIIT/status/1928784110811742389?s=19)

- [ ] **Wait,  Holy crap, read this! New open source code to "evolve" - hell yeah**
  > ğŸ“ [Jeff Clune (@jeffclune) on X](https://x.com/jeffclune/status/1928291576129933595?s=19)
  
  <details>
  <summary>ğŸ’¬ Comments (2)</summary>
  
  **Comment 1:** https://www.theregister.com/2025/06/02/self_improving_ai_cheat/
  
  **Comment 2:** https://x.com/LearningLukeD/status/1929816302186910043?s=19
  
  </details>

- [ ] **Free open source graph memory**
  > ğŸ“ [GitHub - topoteretes/cognee: Memory for AI Agents in 5 lines of code](https://github.com/topoteretes/cognee)
  
# Newly added after June 2025. . . 

- [ ] Notes from keen: plasticity vs generalizations  `This is hard, because we really don't have strong theories of either, but it feels like there might be an intrinsic conflict that should be actively addressed instead of passively accepted. Generalization is an ignoring of details, while plasticity involves recognizing new patterns that are currently meaningless to you. Primacy bias, recency bias Facts versus understanding -- the products of reinforcement learning in policies and value functions are sort of fundamentally different from simple traces of environment interactions. You mine facts for understanding Generalization is not well founded. CNNs have some helpful induct`

- [ ] Agents Play Thousands of 3D Video Games
  - I need to review this research - this is the guy that built that behavior tree thing!! The TenCent thing. 
  - https://arxiv.org/abs/2503.13356
  
- [ ] 