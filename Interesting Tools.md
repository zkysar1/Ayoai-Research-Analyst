# 📋 Interesting Tools

- [ ] **Great article on how to get tensoner flow machined learned model into roblox**
  > 📝 https://devforum.roblox.com/t/machine-learning-in-roblox-with-tensorflow-and-webservers/1298582

- [ ] **What does a transformer mean?  Learn it and see if I need to build it**

    - [ ] **What is a Transformer vs. a gated RNN?**
    > 📝 "Transformers have increasingly outperformed gated RNNs in obtaining new state-of-the-art results on supervised tasks involving text sequences."

- [ ] **PyTorch is a MetaAi based company, that says it is free for experimental stuff.  It looks tempting, but I would not be able to use it long term.  Maybe I should just build something internally, that looks at correlations and call it day.**
  > 📝 [PyTorch](https://ai.facebook.com/tools/pytorch/)
  
  <details>
  <summary>💬 Comments (2)</summary>
  
  **Comment 1:** Just use the book in the model, and start there!?!
  
  **Comment 2:** The model does not need to be that deep if I gather all the data needed and exported the controls. Hmm. I could build hte correlation model in java, super fast and make a fast api and make it free. Start small, right. Maybe I am spending too much time with research these ai models. Hmm.
  
  </details>

- [ ] **Maybe I need to review that AI learning class again,  And review some of the code and see if I can get it working,etc.  Then my feet will be wet with ideas.  I need to do this before I move back to my model.**

- [ ] **Google this:  recurrent networks classification**
  
  <details>
  <summary>💬 Comments (1)</summary>
  
  **Comment 1:** And yikes, Wharton about this way of catahorizing sequences?!  Sequence Classification with LSTM Recurrent Neural Networks in Python with Keras


  
  </details>

- [ ] **best way to explain a neural network classification**
  
  <details>
  <summary>💬 Comments (1)</summary>
  
  **Comment 1:** Cool article here that almost explains how to solve it without using a service:  https://towardsdatascience.com/the-complete-guide-to-neural-networks-multinomial-classification-4fe88bde7839
  
  </details>

- [ ] **Dang, this game AI from black and white looks super cool!!!**
  > 📝 https://www.cs.rochester.edu/~brown/242/assts/termprojs/games.pdf
  
  <details>
  <summary>💬 Comments (7)</summary>
  
  **Comment 1:** This idea of a planner would make creatures much more powerful.
Instead of giving creatures one command at a time and having to wait for that
task to be completed to give the creature another command, the user could
simply create a list of goals that it wishes for the creature to complete [3].
Individual goals could be given importance values that give the creature an idea
of what goals should be more immediately met. In addition to listing goals and
importance, the user could specify a specific search function and search limit so
that the planner doesn't waste too many cycles chasing after impossible goal
states. Once all the goal state information is listed the planner could run in the background and upon completion return the best sequence of actions that satisfy
the user's needs. This list could then be sent from the user to the creature so
that the creature could get to work on its newly created plan of actions. A
planner would give the user more time to spend helping its villagers or doing
missions since its creature could be given a plan that may take a considerable
amount of time and accomplish many tasks. Of course, there would have to be
restrictions in the actions that the planner can give to the creature. Otherwise the
user could give the creature a list of actions that may train the creature very
efficiently and that would take the fun and challenge out of having to manually
train and nurture one's creature. One possible solution is that the planner could
be a special tool that is only unlocked once a user's creature has reached a
certain intelligence level
  
  **Comment 2:** In his review of the AI system he created for “Black and White”, Richard
Evans writes, “A decision tree is built by looking at the attributes which best
divide the learning episodes into groups with similar feedback values. The best
decision tree is the one that minimizes entropy, a measure of how disordered the
feedbacks are. The algorithm used to dynamically construct decision-trees to
minimize entropy is based on (Ross) Quinlan’s ID3 system.” [4]
  
  **Comment 3:** it does not yet know what type of object satisfies its hunger best. It may see a
fence and instantly walk over and take a bite out of it. It will then realize that the
fence did not satisfy its hunger well and tasted horrible in the process. The
creature will alter its internal food decision tree as to keep it from eating fences in
the future [14].
  
  **Comment 4:** After a creature completes an
action to satisfy a certain desire it will look at how well that desire was satisfied
and adjust its internal weight structure accordingly [4].
  
  **Comment 5:** This method is used alongside with rules-based AI (situational calculus) to give
creatures their basic intelligence about objects. This scripted-AI is the most
popular form of artificial intelligence found in games today [2]. Decision trees
represent agents’ beliefs about general types of objects. Finally, neural networks
of perceptrons represent desires [5].
  
  **Comment 6:** Strength of obstructions to walking:
object.man-made.fence->1.0
object.natural.body-of-water.shallow-river->0.5
object.natural.rock->0.1
  
  **Comment 7:** Markie pointed me to this one
  
  </details>

- [ ] **Notes on white board**
  
  <details>
  <summary>💬 Comments (2)</summary>
  
  **Comment 1:** Took that photo on Nov 8 because stated to learn stomp lol.  I think I have all those notes down, I need to confirm. 
  
  **Comment 2:** 
  
  </details>

- [ ] **[Reinforcement Learning : Markov-Decision Process (Part 1) | by blackburn | Towards Data Science](https://towardsdatascience.com/introduction-to-reinforcement-learning-markov-decision-process-44c533ebf8da)**

- [ ] **Link to someone running 1000 npcs and a video**
  > 📝 https://devforum.roblox.com/t/achieving-mass-npc-count/263949

- [ ] **Who is this?**
  > 📝 [GitHub - ivyraine/agentcraft: AI Agent Simulation generates Minecraft Settlements](https://github.com/ivyraine/agentcraft)

- [ ] **Awesome take from tesla**
  > 📝 Idealism is the main atecedant?!
  
  <details>
  <summary>💬 Comments (1)</summary>
  
  **Comment 1:** Nikola Tesla Explains His Philosophy On Life

“We are all automatons,” he reflected, “obeying external influences. We are entirely under the control of agents that beat on our senses from all directions of the outside world. Being merely receivers from the outside, it is a very important question how good the receivers are - some are sensitive and receive accurately. Others are sluggish and their reception is blurred. The individual who is a better machine has so much greater chance of achieving success and happiness. An individual who is an offender of law is a machine in which one or another organ has been deranged, so that the responses are no longer accurate.

“There is no chance in nature, although the modern theory of indeterminacy attempts to show scientifically that events are governed by chance. I positively deny that. The causes and effects, however complex, are intimately linked, and the result of all inferences must be inevitably fixed as by a mathematical formula.

“I also absolutely deny the existence of individuality. It took me not less than twenty years to develop a faculty to trace every thought or act of mine to an external influence. We are just waves in time and space, changing continuously, and the illusion of individuality is produced through the concatenation of the rapidly succeeding phases of existence. What we define as likeness is merely the result of the symmetrical arrangement of molecules which compose our body.”

Says There Is No Soul

“How about the soul - the spirit?” he was asked.

“Ah,” he exclaimed, “but there is no soul or spirit. These are merely expressions of the functions of the body. These life functions cease with death and so do soul and spirit.

“What humanity needs is ideals. Idealism is the force that will free us from material fetters.”

("Tesla Seeks to Send Power to Planets." New York Times, July 11th, 1931.)

Dr. Nikola Tesla. 🧔🏻‍♂️❤️🌍
  
  </details>

- [ ] **Julian Togelius is an Associate Professor of Computer Science and Engineering at NYU, and Cofounder and research director at modl.ai**
  > 📝 [‎TalkRL: The Reinforcement Learning Podcast: Julian Togelius on Apple Podcasts](https://podcasts.apple.com/us/podcast/julian-togelius/id1478198107?i=1000622243973)
  
  <details>
  <summary>💬 Comments (9)</summary>
  
  **Comment 1:** Other things happening in rl?  Dreamer.  Offline q learning to work well is boring interesting.   The things that team does to work well is simple. Sevra Laveen?  Quality diversity algorithm in rl, is where he goes looking.
  
  **Comment 2:** Open ended learning.  His heart still beats for revolutionary algoythems.
  
  **Comment 3:** We need reinforcement learning foundation models that can generalize.  Rl is brittle to a color scheme and other things,  how to get rid of the brittlness?
  
  **Comment 4:** He wants rl models to go the way of llms, where you ever aprompt, and the model is open sourced 
  
  **Comment 5:** Both Jack's space and dreamer version three do vecterizations of environments.   What is that?  What is a vectorization of an environment?
  
  **Comment 6:** Dreamer version 3, that can be more efficient at getting to high performance. 
  
  **Comment 7:** Jacks space rl that can do the rl loop much faster?  This will allow us to train faster
  
  **Comment 8:** Choose your weapon, survival techniques for depressed academics
  
  **Comment 9:** Open ended learning.  The other one I listened to was about multi model.  Abs they have to communicate 
  
  </details>

- [ ] **Jakob Foerster on Multi-Agent learning, Cooperation vs Competition, Emergent Communication, Zero-shot coordination, Opponent Shaping, agents for Hanabi and Prisoner's Dilemma, and more.**
  > 📝 [‎TalkRL: The Reinforcement Learning Podcast: Julian Togelius on Apple Podcasts](https://podcasts.apple.com/us/podcast/julian-togelius/id1478198107?i=1000622243973)
  
  <details>
  <summary>💬 Comments (18)</summary>
  
  **Comment 1:** big question is how can we replace the need for data with simulation and methods that
improve themselves in simulation and this is a big sort of again going back to one of the blind
spots right if we're thinking this this to the to the end the current the current hype train
right what is the final stop of this hype train and what what happens next so i heard some of
  
  **Comment 2:** Jacob Beck and
rest of Wario recently presenting their their meta RL survey paper and so and so I wanted to see
you wanted to hear how how you you relate that to to meta RL so meta self-play that is a phrase that
I have not heard before is that a new thing with and are you are you quoting a phrase here in your
  
  **Comment 3:** Meta reinforcement learning, 44:30
  
  **Comment 4:** meta RL survey paper and so and so I wanted to see
you wanted to hear how how you you relate that to to meta RL so meta self-play that is a phrase that
I have not heard before is that a new thing with and are you are you quoting a phrase here in your
  
  **Comment 5:** Meta fucking self-play....  that's me
  
  **Comment 6:** because based on my and your last policy the learning algorithm in the other agent is going
to induce a state transition a new policy that comes due to the learning process so this is
meta reinforcement learning in a specific setting and more interestingly we get to meta self-play
which is when we combine two mforce agents that learn to shape another shaper so shaping is again
useful opponent shaping here right you have a learning you have a learning agent something
like a ppo agent that's maximizing its own return doing essentially independent learning in the
prison's dilemma and there were meta learning another ppo agent that can learn to optimally
  
  **Comment 7:** Shape another shaper....
  
  **Comment 8:** player's learning step
learning step okay learning step this is it this is the crucial part because how they affect the
policies the current policies that's really done by rl right reinforcement learning gives me time
horizons i can just play a thousand times samples until the end of the episode i see how my action
change you have change impact your future actions i like your policy but the big thing is if you
and i are learning agents then these trajectories generated will go into your learning algorithm
right so imagine you have wayment you have tesla these cars are on the road
  
  **Comment 9:** mutual affection become quite likely and this has been a focus of of this this line of work
how do we do machine learning when our decisions are influencing other learning systems in the long
run and it's all the unbelievable opponent shaping and i'm happy to talk more about any of the
recent papers or methods in that space so you're talking about policies that are choosing actions
policies that are choosing actions based on how they will affect the other player's policy in
future is that is that what you're getting to how they will affect the other player's learning step
learning step okay learning step this is it this is the crucial part because how they affect the
policies the current policies that's really done by rl right reinforcement learning gives me time
horizons i can just play a thousand times samples until the end of the episode i see how my action
  
  **Comment 10:** we would like to have agents that can actually account for the fact that other players are there
and are learning and realize that by reward and punishment they can shape them into cooperation
and that was the key insight behind Lola where we don't maximize don't take a gradient step towards
increasing my current return assuming the other agent's policy is fixed but we differentiate
through the learning step of the opponent in the environment anticipating that our actions will go
into their training data and i will never forget when we first implemented this method this would
do my internship at openai first implementation first run and we get this policy out that
cooperates but it doesn't cooperate blindly it placed it for tat this moment is always going
to be something that i remember in my research career because it was a hard problem we had
honest we had come up with a theory of what is driving the the failure of current methods
and we managed to fix it now lola has obvious issues it's asymmetric it assumes that the other
agents are naive learners it's myopic it only shapes one time step and requires these higher
order derivatives and ever since in particular
  
  **Comment 11:** Said opponent shaping is 
  
  **Comment 12:** hout looking at your hand then suddenly all you know is this card is red because that's
revealed by the environment but you have no idea about why I said this because I would have said
this randomly anyway and that's the main idea of belief of belief learning it really mathematically
this method takes away the risk or the ability of having emergent protocols in multi-agent systems
but don't we need some type of conventions in Hanabi for example if you hint this card is a one I
should probably assume that you're telling me this because the card is playable even if it's
not obvious from the current state of the board and you can get this out by iterating off belief
learning in hierarchies and then you get extremely human compatible gameplay out of OBL and at this
point if you're listening to the podcast I highly recommend to check out our demo of off belief
learning if you're interested and this is at bit.ly and then slash OBL minus demo and you can
actually play with these OBL bots and these are really interesting to play with at least for me
that was quite fascinating to see how Hanabi looks 
  
  **Comment 13:** Off believe learning, obl.  They must agree on a communication protocol.   Like,  when sometime sends a red card,  that may mean something else to another person.   Like, red only means x, never y
  
  **Comment 14:** I wanted to have developed our algorithms that get to this more
sensible way of playing of acting in these tech POMDPs is part observable fully cooperative systems
without requiring vast amounts of human data and the last instance of this is called off-belief
learning which was sort of looking back one of the papers that I've really enjoyed working on
that to me addressed a lot of open questions but it's also paper that's notoriously hard to make
sense of
  
  **Comment 15:** I've used the card
game Hanabi here for the last few years really to develop novel methods in that space
  
  **Comment 16:** A good lever game. 10 levers, one is worth 1, another is worth .9.  But you only get 1 if you both pick it.   Something like this is a good test.   Listen to this test again. Around 20 minutes. 
  
  **Comment 17:** So to put this into one sentence, the problem of multi-agent learning is non-stationarity
and equilibrium selection.
  
  **Comment 18:** So, for example, if you're looking at the world from the perspective of one agent, then
suddenly the actions that other agents take will change the environment that's being faced
by that agent.
And that's called non-stationarity.
  
  </details>

- [ ] **Llm haystack?!**
  > 📝 [Introducing Agents in Haystack: Make LLMs resolve complex tasks | Haystack](https://haystack.deepset.ai/blog/introducing-haystack-agents)

- [ ] **Agents new paper - this is an open source agent I could lok into using? Code is there, with planning and all?? Hmm. . .**
  > 📝 [Paper page - Agents: An Open-source Framework for Autonomous Language Agents](https://huggingface.co/papers/2309.07870)

- [ ] **[Exploring LLMs and AI Education with Luis Serrano - The What's AI Episode Podcast 15](https://youtu.be/NoyQKKQdI0M?si=f6ihshsfau7FWpCv)**
  > 📝 This has fog resources to watch,  like llm University and cohere

- [ ] **[Introduction to Language Models (LLM's, Prompt Engineering, Encoder/Decoder and more)](https://youtu.be/9PGmMdkTZls?si=dpYdRX-K47E0Rfrh)**

- [ ] **Holy shit a 5 hour course?!**
  > 📝 [Create a Large Language Model from Scratch with Python – Tutorial](https://youtu.be/UU1WVnMk4E8?si=sHDq6KPYCiiaA9Mu)

- [ ] **[LLM Foundations (LLM Bootcamp)](https://youtu.be/MyFrMFab6bo?si=r4hPRVoBc3FhBgKu)**

- [ ] **How to edit an encoder?  Llm?**
  > 📝 Next podcast to listen to

- [ ] **What is this? **Cellular Automata?****
  > 📝 https://developmentalsystems.org/sensorimotor-lenia/

    - [ ] **And this: **Flow-Lenia: Towards open-ended evolution in cellular automata through mass conservation and parameter localization****
    > 📝 [hardmaru on X](https://twitter.com/hardmaru/status/1716019268205322508?s=19)

- [ ] **How to drive the browser.**
  > 📝 [GitHub - nat/natbot: Drive a browser with GPT-3](https://github.com/nat/natbot)

- [ ] **What is this?**
  > 📝 [christmas - Wolfram|Alpha](https://www.wolframalpha.com/input?i=christmas&assumption=%7B%22DPClash%22%2C+%22HolidayE%22%2C+%22christmas%22%7D+-%3E+%7B%7B%22ChristmasDay%22%2C+%22Christianity%22%7D%2C+%22dflt%22%7D&assumption=%7B%22C%22%2C+%22christmas%22%7D+-%3E+%7B%22Holiday%22%2C+%22dflt%22%7D&assumption=%7B%22HolidayYear%22%2C+%7B%22ChristmasDay%22%2C+%22Christianity%22%7D%7D+-%3E+%222023%22)

- [ ] **Try to read this today before I give up?**
  > 📝 [Deep Reinforcement Learning: Pong from Pixels](http://karpathy.github.io/2016/05/31/rl/)

- [ ] **Get familiar with how LLMs work**

    - [ ] **What is the difference between vectorize and embeddings**
    - [ ] **Wait, how do I use the instruction tuned ones?**

      - [ ] **Wait what is this?  The instruct model?  Hmmm**
      > 📝 [mistralai/Mistral-7B-Instruct-v0.1 · Hugging Face](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1)
    - [ ] **Read this about fine tuning....**
    > 📝 [anton (@abacaj) on X](https://twitter.com/abacaj/status/1729889359040819474?s=19)
    - [ ] **Read this blog?**
    > 📝 [Teach Llamas to Talk: Recent Progress in Instruction Tuning](https://gaotianyu.xyz/blog/2023/11/30/instruction-tuning/)
    - [ ] **Find out what a knoldge graph + llm is before I build a behavior tree + llm**
    - [ ] **Faster inference with powerline?**
    > 📝 [Meet PowerInfer: A Fast Large Language Model (LLM) on a Single Consumer-Grade GPU that Speeds up Machine Learning Model Inference By 11 Times](https://www.marktechpost.com/2023/12/23/meet-powerinfer-a-fast-large-language-model-llm-on-a-single-consumer-grade-gpu-that-speeds-up-machine-learning-model-inference-by-11-times/)
    - [ ] **Llm plan?  A planner for any agent**
    > 📝 [Jerry Liu (@jerryjliu0) on X](https://twitter.com/jerryjliu0/status/1740778991064408450?s=19)
    - [ ] **Json structured output?!!!**
    > 📝 [Structured Outputs with Anyscale and Zod - Instructor (JS)](https://jxnl.github.io/instructor-js/blog/2024/01/01/patching/)
    - [ ] **Super small llm!**
    > 📝 https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/
    - [ ] **Anther small llm here.   Yes, I need to use these to edit my descriptions and such**
    > 📝 [AK (@_akhaliq) on X](https://twitter.com/_akhaliq/status/1748533176547369391?s=19)

- [ ] **This looks like an interesting book on rl.**
  > 📝 [Stefano Albrecht (UoE Agents Group) (@UoE_Agents) on X](https://twitter.com/UoE_Agents/status/1731665070357107066?s=19)

- [ ] **Omg, myself was on this, but after he spoke, there is free coffee where they used bedrock to fine tune llama!!!  I want that so bad,  let's fucking go**
  > 📝 [AWS re:Invent 2023 - Customize FMs for generative AI applications with Amazon Bedrock (AIM247)](https://youtu.be/YY9N7sDoP30?si=xtuDlntSW2nA0WsB)

- [ ] **Read this on desktop to help visualize an llm**
  > 📝 [MatthewBerman (@MatthewBerman) on X](https://x.com/MatthewBerman/status/1731800405036896348?s=09)

- [ ] **Java for llms?  I downloaded it**
  > 📝 [Java and LLMs: are we there yet?](https://medium.com/@mpapadimitriou92/java-and-llms-are-we-there-yet-300cf9418ed7)

- [ ] **Always output json?**
  > 📝 https://twitter.com/jxnlco/status/1743305057645334979?s=19

- [ ] **Try github copilot library for python?!!  Or is it coursor?**

- [ ] **What is gradio, from Mrigank, it's like a streamlit thing?**

- [ ] **Omg, a wrapper around Llms for filling in json, which saves on tokens?**
  > 📝 [Rohan Paul (@rohanpaul_ai) on X](https://twitter.com/rohanpaul_ai/status/1748896116731683171?s=19)

- [ ] **Research I used to build these behavior trees ... best one below I think**
  > 📝 [GitHub - hms-junk/behaviortree.rbxlua: a simple behaviour tree library for roblox lua ported from a lua library ported from javascript](https://github.com/hms-junk/behaviortree.rbxlua)

    - [ ] **This is a cool one, and has some awesome examples. I need to reread about this stack thing. . .**
    > 📝 [Behavior trees for AI: How they work](https://www.gamedeveloper.com/programming/behavior-trees-for-ai-how-they-work)
    - [ ] **Need to add a parrellel conductor in a behavior tree. Also need to add a stack? And add a repeater. . .**
    - [ ] **Should I be using this one instead?!!?!? [GitHub - Defaultio/BehaviorTree3: An optimized rewrite of BehaviorTree](https://github.com/Defaultio/BehaviorTree3)**
    - [ ] **There is a little more description here. THis is the js implementation of the the thing I was working on.  This has json example!!**
    🔵 Low
    > 📝 [GitHub - Calamari/BehaviorTree.js: An JavaScript implementation of Behavior Trees.](https://github.com/Calamari/BehaviorTree.js)
    - [ ] **interesting articles but not meaty**

      - [ ] **I like this tree basics, and it sets up a game for me to try . . . from ground up. This is the droids example I built in java. This one accepts variables and should think about that.**
      > 📝 [Game AI – An Introduction to Behaviour Trees](https://www.javacodegeeks.com/2014/08/game-ai-an-introduction-to-behaviour-trees.html)
      - [ ] **Dang, this one looks awesome, this is java code I like better I think. Link does not work anymore?**
      > 📝 [GitHub - paasovaara/behavior-trees: Simple behavior-tree implementation](https://github.com/paasovaara/behavior-trees)
      - [ ] **[Behavior Trees by Example. AI in an Android game.](https://magicscrollsofcode.blogspot.com/2010/12/behavior-trees-by-example-ai-in-android.html?m=1)**
    - [ ] **I really like this video. I like it for a few reasons. One, is that it describe a way to use events to stop working on something and validate everything in the tree, else evaluate each second. I Am going to need this because a thing can get stuck in a tree. . . I can evaluate this tree in ayoai and not in roblox though, right? Also, I like the enticer concept they had? Also I like that they said every sigle task node followed the same outline. an on enter, on exit, and conditions on top.**
    > 📝 [Behavior Trees: Three Ways of Cultivating Strong AI](https://www.gdcvault.com/play/1012416/Behavior-Trees-Three-Ways-of)
    - [ ] **Omg... parameterizing behavior trees**
    > 📝 Parameterizing Behavior Trees https://people.cs.umass.edu/~fmgarcia/Papers/Parameterizing%20Behavior%20Trees.pdf

- [ ] **Ohh, I need to read this (and read game dev stacks again)**
  > 📝 [The Craft of Behavior Trees](https://medium.com/@sion_denis/the-craft-of-behavior-trees-ab6b181ce21a)

- [ ] **Github to file?!**
  🏷️ EVENING
  > 📝 [Eric Hartford (@erhartford) on X](https://twitter.com/erhartford/status/1767284737788514724?s=19)

- [ ] **Wow what is this?!  Meta gpt?**
  🏷️ EVENING
  > 📝 [MetaGPT (@MetaGPT_) on X](https://twitter.com/MetaGPT_/status/1767965444579692832?s=19)

- [ ] **Wow, here is an awesome set of domain files: [GitHub - AI-Planning/pddl-generators: A collection of PDDL generators, some of which have been used to generate benchmarks for the International Planning Competition (IPC).](https://github.com/AI-Planning/pddl-generators)**

- [ ] **Pddl wiki?!  Supper cool ayo**
  > 📝 [PDDL+ Domain](https://planning.wiki/ref/pddlplus/domain#processes)

- [ ] **Wow, code to force structured output.  I like**
  > 📝 [Lance Martin (@RLanceMartin) on X](https://twitter.com/RLanceMartin/status/1776015679478767698?s=19)

- [ ] **Anthropic tool use**
  > 📝 [Tool use (function calling)](https://docs.anthropic.com/claude/docs/tool-use)

- [ ] **Interesting how to force json**
  > 📝 [Alex (@alexalbert__) on X](https://twitter.com/alexalbert__/status/1778139303639654709?s=19)

- [ ] **Learning Vert.x!!**
  > 📝 Yeah

    - [ ] **You can’t do much in Vert.x-land unless you can communicate with a **Vertx object**.  Vertx vertx = Vertx.vertx();**
    > 📝 Most applications will only need a single Vert.x instance, but it’s possible to create multiple Vert.x instances if you require, for example, isolation between the event bus
    - [ ] **You handle events by providing **handlers** to the Vert.x APIs.**
    - [ ] ****Reactor Pattern** In most cases Vert.x calls your handlers using a thread called an **event loop**. As nothing in Vert.x or your application blocks, the event loop can merrily run around delivering events to different handlers in succession as they arrive.  Because nothing blocks, an event loop can potentially deliver huge amounts of events in a short amount of time. For example a single event loop can handle many thousands of HTTP requests very quickly.**

      - [ ] **Vert.x works differently here. Instead of a single event loop, each Vertx instance maintains several event loops. By default we choose the number based on the number of available cores on the machine, but this can be overridden. This means a single Vertx process can scale across your server, unlike Node.js. We call this pattern the **Multi-Reactor Pattern** to distinguish it from the single threaded reactor pattern.**
      - [ ] **Even though a Vertx instance maintains multiple event loops, any particular handler will never be executed concurrently, and in most cases (with the exception of worker verticles) will always be called using the exact same event loop.**
    - [ ] ****Verticles** Vert.x comes with a simple, scalable, actor-like deployment and concurrency model out of the box that you can use to save you writing your own. This model is entirely optional and Vert.x does not force you to create your applications in this way if you don’t want to. The model does not claim to be a strict actor-model implementation, but it does share similarities especially with respect to concurrency, scaling and deployment.**

      - [ ] **Offload to **Worker Verticles**: If the blocking operation is inherently long-running, consider offloading it to a dedicated worker verticle. Worker verticles are designed to handle blocking operations and don't use the main event loop threads.**
      - [ ] **An application would typically be composed of many verticle instances running in the same Vert.x instance at the same time. The different verticle instances communicate with each other by sending messages on the **event bus****
      - [ ] **Normally you would override the start method like in the example above. -  - When Vert.x deploys the verticle it will call the start method, and when the method has completed the verticle will be considered started. -  - You can also optionally override the stop method. This will be called by Vert.x when the verticle is undeployed and when the method has completed the verticle will be considered stopped.**
      - [ ] ****Standard Verticles** These are the most common and useful type - they are always executed using an event loop thread. We’ll discuss this more in the next section. **Worker Verticles** These run using a thread from the worker pool. An instance is never executed concurrently by more than one thread.**
      - [ ] **Waiting for deployment to complete - Verticle deployment is asynchronous and may complete some time after the call to deploy has returned. -  - If you want to be notified when deployment is complete you can deploy specifying a completion handler:**
      - [ ] **Specifying number of verticle instances - When deploying a verticle using a verticle name, you can specify the number of verticle instances that you want to deploy:**
    - [ ] **Any asynchronous method returns a **Future** object for the result of the call: a success or a failure. You cannot interact directly with the result of a future, instead you need to set a handler that will be called when the future completes and the result is available, like any other kind of event.**

      - [ ] ****Future composition** - compose can be used for chaining futures: when the current future succeeds, apply the given function, that returns a future. When this returned future completes, the composition succeeds.  when the current future fails, the composition fails. Beyond this, Future offers more: map, recover, otherwise, andThen and even a flatMap which is an alias of compose**
    - [ ] ****Context** object - When Vert.x provides an event to a handler or calls the start or stop methods of a Verticle , the execution is associated with a Context. Usually a context is an event-loop context and is tied to a specific event loop thread. So executions for that context always occur on that exact same event loop thread. In the case of worker verticles and running inline blocking code a worker con. will be associated with the execution which will use a thread from the worker thread pool.**
    - [ ] ****Local maps** - Local maps -  allow you to share data safely between different event loops (e.g. different verticles) in the same Vert.x instance.**
    - [ ] ****Json** Unlike some other languages, Java does not have first class support for JSON so we provide two classes to make handling JSON in your Vert.x applications a bit easier.**

      - [ ] **JSON arrays - The  - JsonArray -  class represents JSON arrays. -  - A JSON array is a sequence of values (string, number, boolean). -  - JSON arrays can also contain null values.**
      - [ ] **JSON objects - The  - JsonObject -  class represents JSON objects. -  - A JSON object is basically just a map which has string keys and values can be of one of the JSON supported types (string, number, boolean). -  - JSON objects also support null values.**
    - [ ] ****Buffers** Most data is shuffled around inside Vert.x using buffers.  A buffer is a sequence of zero or more bytes that can read from or written to and which expands automatically as necessary to accommodate any bytes written to it. You can perhaps think of a buffer as smart byte array.**
    - [ ] **Using the **file system** with Vert.x - The Vert.x  - FileSystem -  object provides many operations for manipulating the file system. -  - There is one file system object per Vert.x instance, and you obtain it with  - fileSystem - .**
    - [ ] **What is a steam?  I think this is an api stream?  Like stream the tokens to the page slowly or singing like that?**
    - [ ] ****Json Parser** - You can easily parse JSON structures but that requires to provide the JSON content at once, but it may not be convenient when you need to parse very large structures. -  - The non-blocking JSON parser is an event driven parser able to deal with very large structures. It transforms a sequence of input buffer to a sequence of JSON parse events.**
    - [ ] ****Blocking** you can’t call blocking operations directly from an event loop, as that would prevent it from doing any other useful work. So how can you do this? -  - It’s done by calling executeBlocking with blocking code to execute, as return you get a future completed with the result of the blocking code execution. -  -**

      - [ ] **Do not block the loop!  If your application is not responsive it might be a sign that you are blocking an event loop somewhere. To help you diagnose such issues, Vert.x will automatically log warnings if it detects an event loop hasn’t returned for some time. If you see warnings like these in your logs, then you should investigate.  If you want to turn off these warnings or change the settings, you can do that in the VertxOptions object before creating the Vertx object.**
      - [ ] **An alternative way to run blocking code is to use a worker verticle**
      - [ ] **A worker verticle is always executed with a thread from the worker pool. -  - By default blocking code is executed on the Vert.x worker pool, configured with  - setWorkerPoolSize - . -  - Additional pools can be created for different purposes:**
    - [ ] ****security** If writing a web application it’s highly recommended that you use Vert.x-Web instead of Vert.x core directly for serving resources and handling file uploads. -  - Vert.x-Web normalises the path in requests to prevent malicious clients from crafting URLs to access resources outside of the web root. -  - Similarly for file uploads Vert.x-Web provides functionality for uploading to a known place on disk and does not rely on the filename provided by the client in the upload**
    - [ ] ****Event Bus** - The  - event bus -  is the nervous system of Vert.x. -  - There is a single event bus instance for every Vert.x instance and it is obtained using the method  - eventBus - . -  - The event bus allows different parts of your application to communicate with each other, irrespective of what language they are written in, and whether they’re in the same Vert.x instance, or in a different Vert.x instance.**

      - [ ] **The event bus API is very simple. It basically involves registering handlers, unregistering handlers and sending and publishing messages.**
      - [ ] **Vert.x doesn’t bother with any fancy addressing schemes. In Vert.x an address is simply a string. Any string is valid. However, it is wise to use some kind of scheme, e.g. using periods to demarcate a namespace. -  - Some examples of valid addresses are europe.news.feed1, acme.games.pacman, sausages, and X.**
      - [ ] **Handlers - Messages are received by handlers. You register a handler at an address. -  - Many different handlers can be registered at the same address. -  - A single handler can be registered at many different addresses.**
      - [ ] **Publish / subscribe messaging - The event bus supports publishing messages. -  - Messages are published to an address. Publishing means delivering the message to all handlers that are registered at that address. -  - This is the familiar publish/subscribe messaging pattern.**
      - [ ] **Best-effort delivery - Vert.x does its best to deliver messages and won’t consciously throw them away. This is called best-effort delivery. -  - However, in case of failure of all or parts of the event bus, there is a possibility messages might be lost. -  - If your application cares about lost messages, you should code your handlers to be idempotent, and your senders to retry after recovery.**

- [ ] **Knowledge graph code?!**
  > 📝 [Yohei (@yoheinakajima) on X](https://twitter.com/yoheinakajima/status/1786055928284127292?s=19)

- [ ] **Gemini flash has free finetunning?**

- [ ] **Chatting with Zak's Survey Paper**

    - [ ] **Questions so far**

      - [ ] **"High level thoughts" are my thoughts so far.  Would be interesting to ask the llm to use those and summarize a task list for me?  Or ideas from it.**
      - [ ] **Start off with suggested pseudo code, and ask if it looks ok to accomplish . . .**
      - [ ] **Make definition of what the goal is.  Like a good.**
      - [ ] **Read through the document, and where you feel confident to answer the open questions, please do so.**
      - [ ] **Read through the document, and go visit every page.  If it is a arxiv page, traverse to the “view pdf” link, and fully review the pdf.  Also, refer to the pdf’s references, and go read those too.  Once you see and read everything in full, begin to answer this question:**
      - [ ] **How is Zak, and what do you think he is trying to build?**
      - [ ] **I could add the pseudo code here too?  Then ask what it thinks about it.**
      - [ ] **Prompt:  given the pdf, what "method" would you choose for reflection and refinement.  Or,  for memory.  So once I hit my level buckets,  abs the processes in those buckets,  we can finalize the methods.**
    - [ ] **Can be found at this link:**
    - [ ] **Wait,  I like these prompts too chat with my paper  ...  and the repos that these papers share?**
    > 📝 [Deedy (@deedydas) on X](https://x.com/deedydas/status/1802529105860252129?s=19)

- [ ] **Prompt notes**
  > 📝 [Ilya Sutskever (Parody) (@ilyasutsk) on X](https://x.com/ilyasutsk/status/1832211266129293618?s=19)

- [ ] **Clone any website?!  [MatthewBerman (@MatthewBerman) on X](https://x.com/MatthewBerman/status/1886084141025824886?s=19)**

- [ ] **Make text into an image.  The text that uses slashes and stuff to make art.  Put this on top of each of my java files...**
  > 📝 https://codepen.io/Mikhail-Bespalov/pen/JoPqYrz

- [ ] **[Here’s how I use LLMs to help me write code](https://simonwillison.net/2025/Mar/11/using-llms-for-code/)**
  > 📝 Read how to code with llms here.  This could save me time.  Already read it March 18 2025

- [ ] **Try this agent out instead of openai?!  This was Jens idea!!  The tasks seem easy to automate. [Charly Wargnier (@DataChaz) on X](https://x.com/DataChaz/status/1900189310256853124?s=19)**

- [ ] **Wow, list of free apis!!**
  > 📝 [GitHub - public-apis/public-apis: A collective list of free APIs](https://github.com/public-apis/public-apis)

- [ ] **These guys may be building the same thing I'm building, damn!!**
  > 📝 [@levelsio (@levelsio) on X](https://x.com/levelsio/status/1901963649930928177?s=19)

- [ ] **Wait, so this tool, https://www.epicgames.com/site/en-US/news/loci-is-now-a-part-of-epic-games, it makes meta data fur 3d objects.  Huh, hell yeah.   That is kind of what we need,  no?!**

- [ ] **What is this agent to agent thing?**
  > 📝 [Dan Mac (@daniel_mac8) on X](https://x.com/daniel_mac8/status/1909981379129135305?s=19)

- [ ] **Letta , statefill llm seems cool!!**
  > 📝 [Letta](https://www.letta.com/)

    - [ ] **[Tom Dörr (@tom_doerr) on X](https://x.com/tom_doerr/status/1910893898349551965?s=19)**
    - [ ] **Letta (formerly MemGPT) is the stateful agents framework with memory, reasoning, and context management.**

- [ ] **Github llm converter**
  > 📝 [Matt Shumer (@mattshumer_) on X](https://x.com/mattshumer_/status/1913282296557224431?s=19)

- [ ] **Read this from nous research, new research [Nous Research (@NousResearch) on X](https://x.com/NousResearch/status/1917299865060794484?s=19)**
  🏷️ COMPUTER
  > 📝 Like, I could hook up my environment to their environment and train something?   What are the other other llms, like the maze?

- [ ] **Omg, claude and code?!  Read this:  [GitHub Actions - Anthropic](https://docs.anthropic.com/en/docs/claude-code/github-actions)**

- [ ] **I left off at page 31, I still like the quote on first page the best.**
  > 📝 [Rick Rubin | The Way of Code: The Timeless Art of Vibe Coding](https://wayofcode.com/#31)

- [ ] **Turn any api into a mcp server!**
  > 📝 [Santiago (@svpino) on X](https://x.com/svpino/status/1927323347760603138?s=19)

- [ ] **Google stick can make uis?!  Mmmmm**
  > 📝 [Everyone’s looking to get in on vibe coding — and Google is no different with Stitch, its follow-up to Jules](https://venturebeat.com/ai/everyones-looking-to-get-in-on-vibe-coding-and-google-is-no-different-with-stitch-its-follow-up-to-jules/)

- [ ] **Visualize github as a graph**
  > 📝 [Charly Wargnier (@DataChaz) on X](https://x.com/DataChaz/status/1928367291890098337?s=19)

- [ ] **Try this to improve prompt**
  > 📝 [Meera | AI Tools & News (@MeeraAIIT) on X](https://x.com/MeeraAIIT/status/1928784110811742389?s=19)

- [ ] **Wait,  Holy crap, read this! New open source code to "evolve" - hell yeah**
  > 📝 [Jeff Clune (@jeffclune) on X](https://x.com/jeffclune/status/1928291576129933595?s=19)
  
  <details>
  <summary>💬 Comments (2)</summary>
  
  **Comment 1:** https://www.theregister.com/2025/06/02/self_improving_ai_cheat/
  
  **Comment 2:** https://x.com/LearningLukeD/status/1929816302186910043?s=19
  
  </details>

- [ ] **Free open source graph memory**
  > 📝 [GitHub - topoteretes/cognee: Memory for AI Agents in 5 lines of code](https://github.com/topoteretes/cognee)